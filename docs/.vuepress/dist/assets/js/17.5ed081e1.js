(window.webpackJsonp=window.webpackJsonp||[]).push([[17],{167:function(e,t,o){"use strict";o.r(t);var n=o(0),a=Object(n.a)({},function(){this.$createElement;this._self._c;return this._m(0)},[function(){var e=this,t=e.$createElement,o=e._self._c||t;return o("div",{staticClass:"content"},[o("h1",{attrs:{id:"converting-non-isf-glsl-shaders-to-isf"}},[o("a",{staticClass:"header-anchor",attrs:{href:"#converting-non-isf-glsl-shaders-to-isf","aria-hidden":"true"}},[e._v("#")]),e._v(" Converting Non-ISF GLSL shaders to ISF")]),e._v(" "),o("ul",[o("li",[e._v("You should probably replace any calls in your shader to "),o("code",[e._v("texture2D()")]),e._v(" or "),o("code",[e._v("texture2DRect()")]),e._v(" with "),o("code",[e._v("IMG_NORM_PIXEL()")]),e._v(" or "),o("code",[e._v("IMG_PIXEL()")]),e._v(", respectively. Images in ISF- inputs, persistent buffers, etc- can be accessed by either "),o("code",[e._v("IMG_NORM_PIXEL()")]),e._v(" or "),o("code",[e._v("IMG_PIXEL()")]),e._v(", depending on whether you want to use normalized or non-normalized coordinates to access the colors of the image. If your shader isn't using these- if it's using "),o("code",[e._v("texture2D()")]),e._v(" or "),o("code",[e._v("texture2DRect()")]),e._v("- it won't compile if the host application tries to send it a different type of texture.")]),e._v(" "),o("li",[e._v("Many shaders pass in the resolution of the image being rendered (knowing where the fragment being evaluated is located within the output image is frequently useful). By default, ISF automatically declares a uniform vec2 named "),o("code",[e._v("RENDERSIZE")]),e._v(" which is passed the dimensions of the image being rendered.")]),e._v(" "),o("li",[e._v("If the shader you're converting requires a time value, note that the uniform float "),o("code",[e._v("TIME")]),e._v(" is declared, and passed the duration (in seconds) which the shader's been runing when the shader's rendered.")]),e._v(" "),o("li",[e._v("Many shaders don't use (or even acknowledge) the alpha channel of the image being rendered. There's nothing wrong with this- but when the shader's loaded in an application that uses the alpha channel, the output of the shader can look bizarre and unpredictable (though it usually involves something being darker than it should be). If you run into this, try setting gl_FragColor.a to 1.0 at the end of your shader.")]),e._v(" "),o("li",[o("code",[e._v("gl_FragCoord.xy")]),e._v(" contains the coordinates of the fragment being evaluated. "),o("code",[e._v("isf_FragNormCoord.xy")]),e._v(" contains the normalized coordinates of the fragment being evaluated.")]),e._v(" "),o("li",[e._v("While ISF files are fragment shaders, and the host environment automatically generates a vertex shader, you can use your own vertex shader if you'd like. If you go this route, your vertex shader should have the same base name as your ISF file (just use the extension .vs), and the first thing you do in your vertex shader's main function is call "),o("code",[e._v("isf_vertShaderInit();")]),e._v(".")]),e._v(" "),o("li",[e._v("If the shader you're converting requires imported graphic resources, note that the ISF format defines the ability to import image files by adding objects to your JSON dict under the "),o("code",[e._v("IMPORTED")]),e._v(" key. The imported images are accessed via the usual "),o("code",[e._v("IMG_PIXEL()")]),e._v(" or "),o("code",[e._v("IMG_NORM_PIXEL()")]),e._v(" methods. Details on how to do this are listed below, and examples are included.")]),e._v(" "),o("li",[e._v('If your texture doesn\'t look right, make sure your texture coordinates are ranged properly (textures are typically "clamped" by the host implementation, if you specify an out-of-range texture coordinate it may look funny).')])])])}],!1,null,null,null);a.options.__file="ref_converting.md";t.default=a.exports}}]);