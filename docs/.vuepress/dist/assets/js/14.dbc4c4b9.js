(window.webpackJsonp=window.webpackJsonp||[]).push([[14],{170:function(t,e,a){"use strict";a.r(e);var s=a(0),n=Object(s.a)({},function(){var t=this,e=t.$createElement,a=t._self._c||e;return a("div",{staticClass:"content"},[t._m(0),t._v(" "),a("p",[t._v("If you are already somewhat familiar with programming, this quick start guide is a quick way to learn the basics of creating GLSL shaders to meet the ISF specification.  Shaders written in the "),a("a",{attrs:{href:"http://vidvox.github.com/isf/",target:"_blank",rel:"noopener noreferrer"}},[t._v("Interactive Shader Format"),a("OutboundLink")],1),t._v(", also known as ISF, can be used as visual generators, effects and transitions in supported software.")]),t._v(" "),a("p",[t._v("For a more in depth lessons on learning GLSL and ISF you can read the "),a("a",{attrs:{href:"primer_index"}},[t._v("ISF Primer")]),t._v(".  Additionally the "),a("a",{attrs:{href:"ref_index"}},[t._v("ISF Reference Pages")]),t._v(" are a useful set of documents to keep on hand when writing and remixing ISF compositions.  Developers interested in supporting ISF in their own software can visit the "),a("a",{attrs:{href:"https://github.com/mrRay/ISF_Spec/",target:"_blank",rel:"noopener noreferrer"}},[t._v("ISF Specification Page"),a("OutboundLink")],1),t._v(" for detailed information and links to useful sample code.")]),t._v(" "),a("p",[t._v("Finally, the "),a("a",{attrs:{href:"http://vidvox.net/rays_oddsnends/ISF%20tests+tutorials.zip",target:"_blank",rel:"noopener noreferrer"}},[t._v("ISF Test/Tutorial filters"),a("OutboundLink")],1),t._v(" contains many useful test ISF compositions that are useful references.")]),t._v(" "),a("p",[t._v("In this document we will cover the basics of using and writing shaders in ISF.")]),t._v(" "),t._m(1),t._v(" "),a("p",[t._v('{% include image.html file="quickstart/ISF-In-VDMX.png" alt="ISF generator in VDMX" max-width="685" caption="ISF composition being used as a source file in VDMX." %}')]),t._v(" "),a("ul",[a("li",[t._v("Shaders written in the ISF specification can be used in supported environments on desktop, mobile and the web.  To use ISF files in a specific piece of software consult the appropriate documentation.")]),t._v(" "),a("li",[t._v('ISF files that you would like to be globally available to all software on your Mac can be placed in the "/Library/Graphics/ISF" or "~/Library/Graphics/ISF" directories.  Generators, filters and transitions in these directories should generally be automatically available within supported software where applicable.')]),t._v(" "),a("li",[t._v("ISF files can be created, viewed and shared online at the "),a("a",{attrs:{href:"http://interactiveshaderformat.com",target:"_blank",rel:"noopener noreferrer"}},[t._v("interactiveshaderformat.com"),a("OutboundLink")],1),t._v(" website.  Compositions from this site can be downloaded and used in your host software of choice.")]),t._v(" "),a("li",[t._v("ISF shaders can be made as full page standalone webpages, with or without controls.  An example implementation can be found in the "),a("a",{attrs:{href:"https://glitch.com/edit/#!/isf-example?path=README.md",target:"_blank",rel:"noopener noreferrer"}},[t._v("ISF Generator Example on Glitch"),a("OutboundLink")],1),t._v(".")])]),t._v(" "),t._m(2),t._v(" "),t._m(3),t._v(" "),a("p",[t._v("You can create ISF compositions using a variety of different tools:")]),t._v(" "),a("ul",[a("li",[t._v("There is a free "),a("a",{attrs:{href:"http://interactiveshaderformat.com",target:"_blank",rel:"noopener noreferrer"}},[t._v("ISF Editor online"),a("OutboundLink")],1),t._v(".")]),t._v(" "),a("li",[t._v("There is a free "),a("a",{attrs:{href:"https://www.vidvox.net/download/ISF_Editor_2.9.7.3.dmg",target:"_blank",rel:"noopener noreferrer"}},[t._v("ISF Editor for Mac"),a("OutboundLink")],1),t._v(".")]),t._v(" "),a("li",[t._v('You can use any standard text editor.  If you are using an app like TextEdit, make sure to use the "Make Plain Text" option from the "Format" menu.')]),t._v(" "),t._m(4)]),t._v(" "),a("p",[t._v('To create your first ISF composition, open the tool of your choice, create a new file and save it with the title "myshader.fs".')]),t._v(" "),a("p",[t._v('In this case the ".fs" file extension stands for "fragment shader" which is the particular type of shader we will be writing for this first example.')]),t._v(" "),a("p",[t._v('Copy and paste the following code into the text editor area and then save the document.  If you are working one of the live updating apps, your output should render a solid orange color.  If you are working in a text editor, you should be able to load the "myshader.fs" into the host application of your choice as a generator file.')]),t._v(" "),t._m(5),a("p",[t._v("This ISF composition is made up of two parts - a JSON blob at the top that describes the shader and below that is section of GLSL code.  The contents will vary but every ISF composition you create will have these two things in a .fs file.")]),t._v(" "),t._m(6),t._v(" "),t._m(7),t._v(" "),a("p",[t._v('{% include image.html file="quickstart/All-Orange.png" alt="Orange generator in ISF Editor" max-width="720" caption="Every pixel is orange example in the ISF Editor." %}')]),t._v(" "),t._m(8),t._v(" "),t._m(9),t._v(" "),a("p",[t._v("Within the ISF specification, there are several useful uniforms that are always available to use within your shaders.")]),t._v(" "),a("p",[t._v("A few of the most important automatic uniforms in ISF are:")]),t._v(" "),t._m(10),t._v(" "),a("p",[t._v('Try creating a new shader called "cartesian coordinates.fs" and pasting in the following code:')]),t._v(" "),t._m(11),a("p",[t._v("The output of this example should vary red over the x-axis and green over the y-axis.  While not particularly interesting, rendering the coordinate space in this fashion is often useful in debugging more complicated shaders.")]),t._v(" "),t._m(12),t._v(" "),t._m(13),t._v(" "),a("p",[t._v('Next create another shader called "time animation.fs" and paste in the following code:')]),t._v(" "),t._m(14),t._m(15),t._v(" "),a("p",[t._v('{% include image.html file="quickstart/Timed-Animation.gif" alt="Timed animation example" max-width="480" caption="Timed animation loop in ISF Editor preview." %}')]),t._v(" "),t._m(16),t._v(" "),t._m(17),t._v(" "),t._m(18),t._v(" "),t._m(19),t._v(" "),a("p",[t._v('You can either create a new shader for this, or modify the "myshader.fs" that you\'ve already started.')]),t._v(" "),t._m(20),a("p",[t._v('{% include image.html file="quickstart/ISF-Editor-Add-Inputs.png" alt="Adding inputs in the ISF Editor" max-width="720" caption="Adding inputs in the ISF Editor." %}')]),t._v(" "),t._m(21),t._v(" "),t._m(22),t._v(" "),t._m(23),t._v(" "),t._m(24),t._m(25),t._v(" "),t._m(26),t._v(" "),t._m(27),t._v(" "),t._m(28),t._v(" "),a("p",[t._v('Create a new shader and save it with the name "firstFX.fs".')]),t._v(" "),a("p",[t._v('As an important note, if you are on a Mac, be sure to save this file to the "~/Library/Graphics/ISF" directory if you would like this effect to be available to host application software.  In the ISF Editor for Mac there is a button in the interface to quickly navigate the browser to this directory.')]),t._v(" "),a("p",[t._v("Now copy and paste the following code into your editor and save the file:")]),t._v(" "),t._m(29),a("p",[t._v("This very simple example demonstrates the two important details when creating image filters:")]),t._v(" "),t._m(30),t._v(" "),a("p",[t._v('{% include image.html file="quickstart/ISF-Image-Inputs.png" alt="Creating ISF FX" max-width="720" caption="Adding an image input in the ISF Editor to create an FX." %}')]),t._v(" "),t._m(31),t._v(" "),t._m(32),t._v(" "),a("p",[t._v("Though not required, ISF allows for compositions to include an optional vertex shader.  This can be useful when creating compositions that make use of pixel look up for convolution kernels or other operations that are best applied as vertex manipulation stage.")]),t._v(" "),a("p",[t._v('The convention for using a vertex shader within ISF is to simply create a file with the same name as your fragment shader but with a ".vs" extension.')]),t._v(" "),a("p",[t._v('Here we will create a pair of files called "passthru.fs" and "passthru.vs" as a starting point for an ISF that uses a vertex shader.')]),t._v(" "),a("p",[t._v("If you are using the ISF Editor for Mac or the web, instead of creating a new text file, simply go to the VS tab within the editor panel and save the document; the .vs file will automatically be created for you.")]),t._v(" "),a("p",[t._v("For the vertex shader, copy and paste the following code:")]),t._v(" "),t._m(33),a("p",[t._v("And it match up with a corresponding boring passthru.fs that looks like this:")]),t._v(" "),t._m(34),a("p",[t._v('{% include image.html file="quickstart/Vertex-Shader-Editing.png" alt="Editing Vertex Shader in ISF Editor" max-width="720" caption="Editing Vertex Shader in the ISF Editor." %}')]),t._v(" "),a("p",[t._v("The two important details here are:")]),t._v(" "),t._m(35),t._v(" "),t._m(36),t._v(" "),t._m(37),t._v(" "),t._m(38),t._v(" "),t._m(39),t._v(" "),a("p",[t._v("While GLSL is incredibly powerful, some advanced composition ideas require combining the results of multiple shader compositions at different resolutions in order to create a final output.  ISF adds a convention for creating shaders that have multiple render passes that can reference each other making it possible to make complex creations.")]),t._v(" "),a("p",[t._v("Like with other properties we have seen so far, setting up multiple render passes involves adding something to both our JSON blob and our GLSL code.")]),t._v(" "),a("p",[t._v('From the set of ISF Tests + Tutorial shaders is the "Test-MultiPassRendering.fs" example of using multiple render passes:')]),t._v(" "),t._m(40),a("p",[t._v("The three important details here are:")]),t._v(" "),t._m(41),t._v(" "),t._m(42),t._v(" "),t._m(43),t._v(" "),a("p",[t._v("Another useful way that ISF extends GLSL is with persistent buffers which make it possible to retain image data between render passes.")]),t._v(" "),t._m(44),t._v(" "),a("p",[t._v('From the set of ISF Tests + Tutorial shaders is the "Test-PersistentBuffer.fs" example of using persistent buffers:')]),t._v(" "),t._m(45),a("p",[t._v('In this code, the result of each execution of the shader is stored in "bufferVariableNameA", which is then used in the next pass.  The "blurAmount" variable specifies how much to mix between the new pixel and the old one.  This technique is often used to create feedback style effects.')]),t._v(" "),t._m(46),t._v(" "),t._m(47),t._v(" "),t._m(48),t._v(" "),a("p",[t._v("Though GLSL as a language has no concept of sound data, many developers have found ways to writes audio-visualizers by converting audio into a format that can be passed to shaders.    As one of its extensions to the language, ISF includes a standard way for host software to pass in audio waveforms and FFT information for this purpose.")]),t._v(" "),t._m(49),t._v(" "),t._m(50),t._v(" "),t._m(51),t._m(52),t._v(" "),a("p",[t._v('The "audioFFT" type works in a similar fashion, with the results packed into an image where the y-axis representing individual channels and the x-axis holding the results for individual frequency bins.')]),t._v(" "),a("p",[t._v('{% include image.html file="quickstart/Audio-Inputs.png" alt="Audio Reactive Shader in ISF Editor" max-width="720" caption="Shader with raw audio and FFT waveform inputs in the ISF Editor." %}')]),t._v(" "),t._m(53),t._v(" "),t._m(54),t._v(" "),a("p",[t._v("In many cases, GLSL code can be easily adapted to ISF by adding the JSON blob and making a few minor changes to a few function and variable names.")]),t._v(" "),t._m(55),t._v(" "),a("p",[t._v("Here is a list of tips that address many of the common differences:")]),t._v(" "),t._m(56),t._v(" "),t._m(57),t._v(" "),t._m(58),t._v(" "),a("p",[t._v("This page was designed to demonstrate some of the core ideas of the Interactive Shader Format as quickly as possible - but there is a lot more to learn, both about ISF and GLSL.")]),t._v(" "),a("p",[t._v("Here are a few resources you may want to check out next:")]),t._v(" "),a("ul",[t._m(59),t._v(" "),t._m(60),t._v(" "),a("li",[t._v("Visit the "),a("a",{attrs:{href:"http://interactiveshaderformat.com",target:"_blank",rel:"noopener noreferrer"}},[t._v("ISF Sharing Site"),a("OutboundLink")],1),t._v(" where you can find lots of compositions to learn from, remix, or just use directly in host applications.")]),t._v(" "),a("li",[t._v("The full "),a("a",{attrs:{href:"https://github.com/mrRay/ISF_Spec/",target:"_blank",rel:"noopener noreferrer"}},[t._v("ISF Specification Page"),a("OutboundLink")],1),t._v(" contains detailed information for developers.")])])])},[function(){var t=this.$createElement,e=this._self._c||t;return e("h2",{attrs:{id:"introduction-to-the-isf-quick-start"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#introduction-to-the-isf-quick-start","aria-hidden":"true"}},[this._v("#")]),this._v(" Introduction to the ISF Quick Start")])},function(){var t=this.$createElement,e=this._self._c||t;return e("h2",{attrs:{id:"using-isf-compositions"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#using-isf-compositions","aria-hidden":"true"}},[this._v("#")]),this._v(" Using ISF Compositions")])},function(){var t=this.$createElement,e=this._self._c||t;return e("p",[this._v("Additional discussion and examples can be found in the "),e("a",{attrs:{href:"primer_chapter_3"}},[this._v("ISF Primer chapter on using ISF Compositions")]),this._v(".")])},function(){var t=this.$createElement,e=this._self._c||t;return e("h2",{attrs:{id:"creating-isf-compositions"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#creating-isf-compositions","aria-hidden":"true"}},[this._v("#")]),this._v(" Creating ISF Compositions")])},function(){var t=this.$createElement,e=this._self._c||t;return e("li",[this._v("Additional discussion about development tools can be found in the "),e("a",{attrs:{href:"primer_chapter_3"}},[this._v("ISF Primer chapter on creating ISF Compositions")]),this._v(".")])},function(){var t=this,e=t.$createElement,a=t._self._c||e;return a("div",{staticClass:"language-glsl extra-class"},[a("pre",{pre:!0,attrs:{class:"language-glsl"}},[a("code",[a("span",{attrs:{class:"token comment"}},[t._v('/*{\n\t"DESCRIPTION": "Every pixel is orange",\n\t"CREDIT": "by VIDVOX",\n\t"ISFVSN": "2.0",\n\t"CATEGORIES": [\n\t\t"TEST-GLSL FX"\n\t]\n}*/')]),t._v("\n\n"),a("span",{attrs:{class:"token keyword"}},[t._v("void")]),t._v(" "),a("span",{attrs:{class:"token function"}},[t._v("main")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n\tgl_FragColor "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{attrs:{class:"token keyword"}},[t._v("vec4")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{attrs:{class:"token number"}},[t._v("1.0")]),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{attrs:{class:"token number"}},[t._v("0.5")]),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{attrs:{class:"token number"}},[t._v("0.0")]),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{attrs:{class:"token number"}},[t._v("1.0")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),a("span",{attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])])},function(){var t=this,e=t.$createElement,a=t._self._c||e;return a("ul",[a("li",[t._v("In the JSON section, the "),a("code",[t._v("DESCRIPTION")]),t._v(", "),a("code",[t._v("CREDIT")]),t._v(", and "),a("code",[t._v("CATEGORIES")]),t._v(" attributes are meta-data that can be used to include useful information about the purpose of the shader, who created it and which category groups the host application should include in.  The "),a("code",[t._v("ISFVSN")]),t._v(" attribute tells the host which version of the ISF specification this shader was written against.  Though each ISF composition must include a JSON section, many of the attributes are optional and several are only used in specific circumstances.  The "),a("a",{attrs:{href:"ref_json"}},[t._v("ISF JSON Reference")]),t._v(" contains a detailed listing of the available options for this section.")]),t._v(" "),a("li",[t._v("In the GLSL section is our "),a("code",[t._v("void main() {}")]),t._v(" function in which the variable "),a("code",[t._v("gl_FragColor")]),t._v(" is set to the color orange.  By convention, this function is called by host applications to render each shader and must be included.")])])},function(){var t=this.$createElement,e=this._self._c||t;return e("p",[this._v("From this starting point, you can replace the contents of the "),e("code",[this._v("void main() {}")]),this._v(" function with other code and set "),e("code",[this._v("gl_FragColor")]),this._v(" to any other color.  With GLSL, the code in this function will execute simultaneously for every single pixel in your image.")])},function(){var t=this.$createElement,e=this._self._c||t;return e("p",[this._v("This is further detailed in the "),e("a",{attrs:{href:"primer_chapter_2"}},[this._v("ISF Primer chapter on the anatomy of an ISF composition")]),this._v(".")])},function(){var t=this.$createElement,e=this._self._c||t;return e("h2",{attrs:{id:"automatically-created-uniforms-and-variables-in-isf"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#automatically-created-uniforms-and-variables-in-isf","aria-hidden":"true"}},[this._v("#")]),this._v(" Automatically Created Uniforms and Variables in ISF")])},function(){var t=this,e=t.$createElement,a=t._self._c||e;return a("ul",[a("li",[a("code",[t._v("isf_FragNormCoord")]),t._v(" which contains the normalized (0.0 to 1.0) coordinate.")]),t._v(" "),a("li",[a("code",[t._v("TIME")]),t._v(" and "),a("code",[t._v("FRAMEINDEX")]),t._v(" which can be used to animate compositions over time.")]),t._v(" "),a("li",[a("code",[t._v("RENDERSIZE")]),t._v(" which contains the pixel dimensions of the output being rendered.")])])},function(){var t=this,e=t.$createElement,a=t._self._c||e;return a("div",{staticClass:"language-glsl extra-class"},[a("pre",{pre:!0,attrs:{class:"language-glsl"}},[a("code",[a("span",{attrs:{class:"token comment"}},[t._v('/*{\n\t"DESCRIPTION": "Show coordinate space",\n\t"CREDIT": "by VIDVOX",\n\t"ISFVSN": "2.0",\n\t"CATEGORIES": [\n\t\t"TEST-GLSL"\n\t]\n}*/')]),t._v("\n\n"),a("span",{attrs:{class:"token keyword"}},[t._v("void")]),t._v(" "),a("span",{attrs:{class:"token function"}},[t._v("main")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n\tgl_FragColor "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{attrs:{class:"token keyword"}},[t._v("vec4")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("isf_FragNormCoord"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("x"),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v("isf_FragNormCoord"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("y"),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{attrs:{class:"token number"}},[t._v("0.0")]),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{attrs:{class:"token number"}},[t._v("1.0")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),a("span",{attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])])},function(){var t=this.$createElement,e=this._self._c||t;return e("p",[this._v("In the ISF References Pages you can find a list of "),e("a",{attrs:{href:"ref_variables"}},[this._v("automatic uniforms in ISF")]),this._v(" and "),e("a",{attrs:{href:"ref_functions"}},[this._v("built-in functions")]),this._v(".")])},function(){var t=this.$createElement,e=this._self._c||t;return e("h2",{attrs:{id:"timed-animations"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#timed-animations","aria-hidden":"true"}},[this._v("#")]),this._v(" Timed Animations")])},function(){var t=this,e=t.$createElement,a=t._self._c||e;return a("div",{staticClass:"language-glsl extra-class"},[a("pre",{pre:!0,attrs:{class:"language-glsl"}},[a("code",[a("span",{attrs:{class:"token comment"}},[t._v('/*{\n\t"DESCRIPTION": "Test animation",\n\t"CREDIT": "by VIDVOX",\n\t"ISFVSN": "2.0",\n\t"CATEGORIES": [\n\t\t"TEST-GLSL"\n\t]\n}*/')]),t._v("\n\n"),a("span",{attrs:{class:"token keyword"}},[t._v("void")]),t._v(" "),a("span",{attrs:{class:"token function"}},[t._v("main")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n\t"),a("span",{attrs:{class:"token keyword"}},[t._v("float")]),t._v(" val "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("isf_FragNormCoord"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("x "),a("span",{attrs:{class:"token operator"}},[t._v("<")]),t._v(" "),a("span",{attrs:{class:"token function"}},[t._v("fract")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("TIME"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{attrs:{class:"token operator"}},[t._v("?")]),t._v(" "),a("span",{attrs:{class:"token number"}},[t._v("1.0")]),t._v(" "),a("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{attrs:{class:"token number"}},[t._v("0.0")]),a("span",{attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\tgl_FragColor "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{attrs:{class:"token keyword"}},[t._v("vec4")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{attrs:{class:"token number"}},[t._v("1.0")]),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{attrs:{class:"token number"}},[t._v("0.5")]),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{attrs:{class:"token number"}},[t._v("0.75")]),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v("val"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),a("span",{attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])])},function(){var t=this.$createElement,e=this._self._c||t;return e("p",[this._v("This code uses the "),e("code",[this._v("TIME")]),this._v(" uniform variable to animate the output.  When the x position of the current coordinate is less than the fraction part of the time in sections the image is filled in with our color, otherwise the pixel is transparent.")])},function(){var t=this.$createElement,e=this._self._c||t;return e("p",[this._v("Further discussion and examples can be found in the "),e("a",{attrs:{href:"primer_chapter_4"}},[this._v("ISF Primer chapter on automatically created uniform variables")]),this._v(".")])},function(){var t=this.$createElement,e=this._self._c||t;return e("h2",{attrs:{id:"adding-interface-controls"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#adding-interface-controls","aria-hidden":"true"}},[this._v("#")]),this._v(" Adding Interface Controls")])},function(){var t=this.$createElement,e=this._self._c||t;return e("p",[this._v("One of the most powerful aspects of ISF is the ability to declare uniform variables such that a host application can automatically create the appropriate interface input controls.  For example a "),e("code",[this._v("float")]),this._v(" type is typically represented as a slider or knob, whereas a "),e("code",[this._v("bool")]),this._v(" would be represented by an on / off toggle button.")])},function(){var t=this.$createElement,e=this._self._c||t;return e("p",[this._v("Going back to our first example, we could add a single uniform variable to this by adding the "),e("code",[this._v("INPUTS")]),this._v(" attribute to the JSON section.")])},function(){var t=this,e=t.$createElement,a=t._self._c||e;return a("div",{staticClass:"language-glsl extra-class"},[a("pre",{pre:!0,attrs:{class:"language-glsl"}},[a("code",[a("span",{attrs:{class:"token comment"}},[t._v('/*{\n\t"DESCRIPTION": "Demonstrates a float input",\n\t"CREDIT": "by VIDVOX",\n\t"ISFVSN": "2.0",\n\t"CATEGORIES": [\n\t\t"TEST-GLSL"\n\t],\n\t"INPUTS": [\n\t\t{\n\t\t\t"NAME": "level",\n\t\t\t"TYPE": "float",\n\t\t\t"LABEL": "Gray Level",\n\t\t\t"DEFAULT": 0.5,\n\t\t\t"MIN": 0.0,\n\t\t\t"MAX": 1.0\n\t\t}\n\t]\n}*/')]),t._v("\n\n"),a("span",{attrs:{class:"token keyword"}},[t._v("void")]),t._v(" "),a("span",{attrs:{class:"token function"}},[t._v("main")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n\tgl_FragColor "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{attrs:{class:"token keyword"}},[t._v("vec4")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("level"),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v("level"),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v("level"),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{attrs:{class:"token number"}},[t._v("1.0")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),a("span",{attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])])},function(){var t=this.$createElement,e=this._self._c||t;return e("p",[this._v("Looking in the "),e("code",[this._v("INPUTS")]),this._v(" section, there is a single element with several attributes.  The two that are required here are "),e("code",[this._v("NAME")]),this._v(" and "),e("code",[this._v("TYPE")]),this._v(' which are set to "level" and "float" respectively.')])},function(){var t=this,e=t.$createElement,a=t._self._c||e;return a("p",[t._v("Additional the optional "),a("code",[t._v("LABEL")]),t._v(", "),a("code",[t._v("MIN")]),t._v(", "),a("code",[t._v("MAX")]),t._v(" and "),a("code",[t._v("LABEL")]),t._v(" attributes are included here.")])},function(){var t=this.$createElement,e=this._self._c||t;return e("p",[this._v('Now instead of the "float" option for '),e("code",[this._v("TYPE")]),this._v(', try this code which uses the "color" option which provides a vec4 uniform variable.')])},function(){var t=this,e=t.$createElement,a=t._self._c||e;return a("div",{staticClass:"language-glsl extra-class"},[a("pre",{pre:!0,attrs:{class:"language-glsl"}},[a("code",[a("span",{attrs:{class:"token comment"}},[t._v('/*{\n\t"DESCRIPTION": "Demonstrates a color input",\n\t"CREDIT": "by VIDVOX",\n\t"ISFVSN": "2.0",\n\t"CATEGORIES": [\n\t\t"TEST-GLSL"\n\t],\n\t"INPUTS": [\n\t\t{\n\t\t  "NAME" : "colorValue",\n\t\t  "TYPE" : "color",\n\t\t  "DEFAULT" : [\n\t\t\t1.0,\n\t\t\t0.5,\n\t\t\t0.25,\n\t\t\t1.0\n\t\t  ]\n\t\t}\n\t]\n}*/')]),t._v("\n\n"),a("span",{attrs:{class:"token keyword"}},[t._v("void")]),t._v(" "),a("span",{attrs:{class:"token function"}},[t._v("main")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n\tgl_FragColor "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" colorValue"),a("span",{attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),a("span",{attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])])},function(){var t=this,e=t.$createElement,a=t._self._c||e;return a("p",[t._v("The "),a("a",{attrs:{href:"ref_json"}},[t._v("ISF JSON Reference")]),t._v(" contains a detailed listing of the various supported input types and attributes which includes conventions for passing in both scalar types like "),a("code",[t._v("float")]),t._v(" and "),a("code",[t._v("bool")]),t._v(", vector types like "),a("code",[t._v("vec2")]),t._v(" (for points) and "),a("code",[t._v("vec4")]),t._v(" (for colors), and special types like image and audio data.")])},function(){var t=this.$createElement,e=this._self._c||t;return e("p",[this._v("Further discussion and examples can be found in the "),e("a",{attrs:{href:"primer_chapter_2"}},[this._v("ISF Primer chapter on the anatomy of an ISF composition")]),this._v(".")])},function(){var t=this.$createElement,e=this._self._c||t;return e("h2",{attrs:{id:"making-image-effect-filters"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#making-image-effect-filters","aria-hidden":"true"}},[this._v("#")]),this._v(" Making Image Effect Filters")])},function(){var t=this.$createElement,e=this._self._c||t;return e("p",[this._v("Part of the ISF specification is a convention for declaring compositions as effects filters which are meant to process incoming image data.  This is accomplished by including an input with the "),e("code",[this._v("TYPE")]),this._v(' set to "image" and setting the '),e("code",[this._v("NAME")]),this._v(' to "inputImage".')])},function(){var t=this,e=t.$createElement,a=t._self._c||e;return a("div",{staticClass:"language-glsl extra-class"},[a("pre",{pre:!0,attrs:{class:"language-glsl"}},[a("code",[a("span",{attrs:{class:"token comment"}},[t._v('/*{\n\t"DESCRIPTION": "demonstrates an invert image filter",\n\t"CREDIT": "by VIDVOX",\n\t"ISFVSN": "2.0",\n\t"CATEGORIES": [\n\t\t"TEST-GLSL FX"\n\t],\n\t"INPUTS": [\n\t\t{\n\t\t\t"NAME": "inputImage",\n\t\t\t"TYPE": "image"\n\t\t}\n\t]\n}*/')]),t._v("\n\n"),a("span",{attrs:{class:"token keyword"}},[t._v("vec3")]),t._v(" invertColor "),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{attrs:{class:"token keyword"}},[t._v("vec3")]),t._v(" c"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n\t"),a("span",{attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),a("span",{attrs:{class:"token number"}},[t._v("1.0")]),t._v(" "),a("span",{attrs:{class:"token operator"}},[t._v("-")]),t._v(" c"),a("span",{attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),a("span",{attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n"),a("span",{attrs:{class:"token keyword"}},[t._v("void")]),t._v(" "),a("span",{attrs:{class:"token function"}},[t._v("main")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n\t"),a("span",{attrs:{class:"token keyword"}},[t._v("vec4")]),t._v("\t\tsrcPixel "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{attrs:{class:"token function"}},[t._v("IMG_NORM_PIXEL")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("inputImage"),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v("isf_FragNormCoord"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\tsrcPixel"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("rgb "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{attrs:{class:"token function"}},[t._v("invertColor")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("srcPixel"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("rgb"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\tgl_FragColor "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" srcPixel"),a("span",{attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),a("span",{attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])])},function(){var t=this,e=t.$createElement,a=t._self._c||e;return a("ul",[a("li",[t._v('Including the "inputImage" as an element in the '),a("code",[t._v("INPUTS")]),t._v(" section of the JSON blob.")]),t._v(" "),a("li",[t._v("Using the "),a("code",[t._v("IMG_NORM_PIXEL()")]),t._v(" function to get the color of a particular normalized pixel.  Within ISF, this function and its non-normalized counterpart "),a("code",[t._v("IMG_PIXEL()")]),t._v(" replace the functions "),a("code",[t._v("texture2D()")]),t._v(" or "),a("code",[t._v("texture2DRect()")]),t._v(".  More information can be found on the "),a("a",{attrs:{href:"ref_functions"}},[t._v("ISF built-in functions")]),t._v(" reference page.")])])},function(){var t=this.$createElement,e=this._self._c||t;return e("p",[this._v("ISF compositions can include more than one image input, making it possible to pass in additional data to be used for things like masking and distortion effects.  Additional information on declaring image inputs and the image filter convention can be found in the"),e("a",{attrs:{href:"ref_json"}},[this._v("ISF JSON Reference")]),this._v(".")])},function(){var t=this.$createElement,e=this._self._c||t;return e("h2",{attrs:{id:"including-vertex-shaders"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#including-vertex-shaders","aria-hidden":"true"}},[this._v("#")]),this._v(" Including Vertex Shaders")])},function(){var t=this,e=t.$createElement,a=t._self._c||e;return a("div",{staticClass:"language-glsl extra-class"},[a("pre",{pre:!0,attrs:{class:"language-glsl"}},[a("code",[a("span",{attrs:{class:"token comment"}},[t._v("//\tpassthru.vs")]),t._v("\n"),a("span",{attrs:{class:"token comment"}},[t._v("//\tput your code in the main() {} function")]),t._v("\n\n"),a("span",{attrs:{class:"token keyword"}},[t._v("varying")]),t._v(" "),a("span",{attrs:{class:"token keyword"}},[t._v("vec2")]),t._v(" translated_coord"),a("span",{attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n"),a("span",{attrs:{class:"token keyword"}},[t._v("void")]),t._v(" "),a("span",{attrs:{class:"token function"}},[t._v("main")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n\t"),a("span",{attrs:{class:"token comment"}},[t._v("//\tmake sure to call this in your custom ISF shaders to perform initial setup!")]),t._v("\n\t"),a("span",{attrs:{class:"token function"}},[t._v("isf_vertShaderInit")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\ttranslated_coord "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" isf_FragNormCoord"),a("span",{attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),a("span",{attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])])},function(){var t=this,e=t.$createElement,a=t._self._c||e;return a("div",{staticClass:"language-glsl extra-class"},[a("pre",{pre:!0,attrs:{class:"language-glsl"}},[a("code",[a("span",{attrs:{class:"token comment"}},[t._v("//\tpassthru.fs")]),t._v("\n"),a("span",{attrs:{class:"token comment"}},[t._v('/*{\n\t"DESCRIPTION": "Passes through each pixel",\n\t"CREDIT": "by VIDVOX",\n\t"ISFVSN": "2",\n\t"CATEGORIES": [\n\t\t"TEST-GLSL FX"\n\t],\n\t"INPUTS": [\n\t\t{\n\t\t\t"NAME": "inputImage",\n\t\t\t"TYPE": "image"\n\t\t}\n\t]\n}*/')]),t._v("\n\n"),a("span",{attrs:{class:"token keyword"}},[t._v("varying")]),t._v(" "),a("span",{attrs:{class:"token keyword"}},[t._v("vec2")]),t._v(" translated_coord"),a("span",{attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n"),a("span",{attrs:{class:"token keyword"}},[t._v("void")]),t._v(" "),a("span",{attrs:{class:"token function"}},[t._v("main")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n\t"),a("span",{attrs:{class:"token comment"}},[t._v("//\tuses the translated_coord provided from the .vs")]),t._v("\n\tgl_FragColor "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{attrs:{class:"token function"}},[t._v("IMG_NORM_PIXEL")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("inputImage"),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v("translated_coord"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),a("span",{attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])])},function(){var t=this.$createElement,e=this._self._c||t;return e("ul",[e("li",[this._v("When including your own vertex shader, make sure to include the "),e("code",[this._v("isf_vertShaderInit();")]),this._v(" that tells the host application to do any initial setup.")]),this._v(" "),e("li",[this._v("In this pair of shaders, the "),e("code",[this._v("varying")]),this._v(" variable is used to pass data from the vs to the fs and it is declared in both documents.")])])},function(){var t=this.$createElement,e=this._self._c||t;return e("p",[this._v("Within the fragment shader, instead of using the traditional "),e("code",[this._v("isf_FragNormCoord")]),this._v(" as our coordinate, the "),e("code",[this._v("translated_coord")]),this._v(" variable passed from the vertex shader is used instead.  This allows us to do translations to our coordinate system within the vertex shader such that they don't need to be recomputed for every render pass to the fragment shader.")])},function(){var t=this.$createElement,e=this._self._c||t;return e("p",[this._v("Also note that any "),e("code",[this._v("uniform")]),this._v(" variables declared in the JSON section of the fragment shader are also automatically available to the vertex shader.")])},function(){var t=this.$createElement,e=this._self._c||t;return e("p",[this._v("Further discussion and examples can be found in the ISF Primer chapters on "),e("a",{attrs:{href:"primer_chapter_5"}},[this._v("using vertex shaders to create a rotation effect")]),this._v(" and "),e("a",{attrs:{href:"primer_chapter_6"}},[this._v("using vertex shaders in convolution filters")]),this._v(".")])},function(){var t=this.$createElement,e=this._self._c||t;return e("h2",{attrs:{id:"multiple-passes"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#multiple-passes","aria-hidden":"true"}},[this._v("#")]),this._v(" Multiple Passes")])},function(){var t=this,e=t.$createElement,a=t._self._c||e;return a("div",{staticClass:"language-glsl extra-class"},[a("pre",{pre:!0,attrs:{class:"language-glsl"}},[a("code",[a("span",{attrs:{class:"token comment"}},[t._v('/*{\n\t"DESCRIPTION": "demonstrates the use of two-pass rendering- the first pass renders to a persistent buffer which is substantially smaller than the res of the image being drawn.  the second pass renders at the default requested size and scales up the image from the first pass",\n\t"CREDIT": "by zoidberg",\n\t"ISFVSN": "2.0",\n\t"CATEGORIES": [\n\t\t"TEST-GLSL FX"\n\t],\n\t"INPUTS": [\n\t\t{\n\t\t\t"NAME": "inputImage",\n\t\t\t"TYPE": "image"\n\t\t}\n\t],\n\t"PASSES": [\n\t\t{\n\t\t\t"TARGET":"bufferVariableNameA",\n\t\t\t"PERSISTENT": true,\n\t\t\t"WIDTH": "$WIDTH/16.0",\n\t\t\t"HEIGHT": "$HEIGHT/16.0"\n\t\t},\n\t\t{\n\t\t\n\t\t}\n\t]\n\t\n}*/')]),t._v("\n\n"),a("span",{attrs:{class:"token keyword"}},[t._v("void")]),t._v(" "),a("span",{attrs:{class:"token function"}},[t._v("main")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n\t"),a("span",{attrs:{class:"token comment"}},[t._v('//\tfirst pass: read the "inputImage"- remember, we\'re drawing to the persistent buffer "bufferVariableNameA" on the first pass')]),t._v("\n\t"),a("span",{attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("PASSINDEX "),a("span",{attrs:{class:"token operator"}},[t._v("==")]),t._v(" "),a("span",{attrs:{class:"token number"}},[t._v("0")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\t"),a("span",{attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n\t\tgl_FragColor "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{attrs:{class:"token function"}},[t._v("IMG_THIS_NORM_PIXEL")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("inputImage"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\t"),a("span",{attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\t"),a("span",{attrs:{class:"token comment"}},[t._v('//\tsecond pass: read from "bufferVariableNameA".  output looks chunky and low-res.')]),t._v("\n\t"),a("span",{attrs:{class:"token keyword"}},[t._v("else")]),t._v(" "),a("span",{attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("PASSINDEX "),a("span",{attrs:{class:"token operator"}},[t._v("==")]),t._v(" "),a("span",{attrs:{class:"token number"}},[t._v("1")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\t"),a("span",{attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n\t\tgl_FragColor "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{attrs:{class:"token function"}},[t._v("IMG_THIS_NORM_PIXEL")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("bufferVariableNameA"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\t"),a("span",{attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),a("span",{attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])])},function(){var t=this,e=t.$createElement,a=t._self._c||e;return a("ul",[a("li",[t._v("The addition of the "),a("code",[t._v("PASSES")]),t._v(" array to the JSON section of our composition.  Here there are defined two passes.\n"),a("ul",[a("li",[t._v("The first renders at 1/16th of the final output and has a special "),a("code",[t._v("TARGET")]),t._v(' name set to "bufferVariableNameA" which allows other render passes to access it.')]),t._v(" "),a("li",[t._v("The second and final render pass has no included attributes and will have a "),a("code",[t._v("RENDERSIZE")]),t._v(' equal to the final output, as determined by the host application (for an image filter typically this will be the same resolution as the "inputImage".')])])]),t._v(" "),a("li",[t._v("Within the GLSL code, the new automatic variable "),a("code",[t._v("PASSINDEX")]),t._v(" is available for determining which render pass is currently being executed.  Like with other uniform variables you can use this in both the fragment and vertex shader stages.")]),t._v(" "),a("li",[t._v('Within the GLSL code, in addition to the "inputImage" variable, the "bufferVariableNameA" is used along with the '),a("code",[t._v("IMG_THIS_NORM_PIXEL")]),t._v(" functions to access pixel data across render passes.")])])},function(){var t=this.$createElement,e=this._self._c||t;return e("p",[this._v("The "),e("a",{attrs:{href:"ref_json"}},[this._v("ISF JSON Reference")]),this._v(" contains a detailed information on declaring multiple render passes.  Further discussion and examples can be found in the "),e("a",{attrs:{href:"primer_chapter_7"}},[this._v("ISF Primer chapter on multiple render passes")]),this._v(".")])},function(){var t=this.$createElement,e=this._self._c||t;return e("h2",{attrs:{id:"persistent-buffers"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#persistent-buffers","aria-hidden":"true"}},[this._v("#")]),this._v(" Persistent Buffers")])},function(){var t=this.$createElement,e=this._self._c||t;return e("p",[this._v("Persistent buffers are an optional attribute that can be attached to any element in the "),e("code",[this._v("PASSES")]),this._v(" section of the JSON blob.")])},function(){var t=this,e=t.$createElement,a=t._self._c||e;return a("div",{staticClass:"language-glsl extra-class"},[a("pre",{pre:!0,attrs:{class:"language-glsl"}},[a("code",[a("span",{attrs:{class:"token comment"}},[t._v('/*{\n\t"DESCRIPTION": "demonstrates the use of a persistent buffer to create a motion-blur type effect. also demonstrates the simplest use of steps: a one-step rendering pass",\n\t"CREDIT": "by zoidberg",\n\t"ISFVSN": "2.0",\n\t"CATEGORIES": [\n\t\t"TEST-GLSL FX"\n\t],\n\t"INPUTS": [\n\t\t{\n\t\t\t"NAME": "inputImage",\n\t\t\t"TYPE": "image"\n\t\t},\n\t\t{\n\t\t\t"NAME": "blurAmount",\n\t\t\t"TYPE": "float"\n\t\t}\n\t],\n\t"PASSES": [\n\t\t{\n\t\t\t"TARGET": "bufferVariableNameA",\n\t\t\t"PERSISTENT": true,\n\t\t\t"FLOAT": true\n\t\t}\n\t]\n\t\n}*/')]),t._v("\n\n"),a("span",{attrs:{class:"token keyword"}},[t._v("void")]),t._v(" "),a("span",{attrs:{class:"token function"}},[t._v("main")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n\t"),a("span",{attrs:{class:"token keyword"}},[t._v("vec4")]),t._v("\t\tfreshPixel "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{attrs:{class:"token function"}},[t._v("IMG_THIS_PIXEL")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("inputImage"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\t"),a("span",{attrs:{class:"token keyword"}},[t._v("vec4")]),t._v("\t\tstalePixel "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{attrs:{class:"token function"}},[t._v("IMG_THIS_PIXEL")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("bufferVariableNameA"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\tgl_FragColor "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{attrs:{class:"token function"}},[t._v("mix")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("freshPixel"),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v("stalePixel"),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v("blurAmount"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),a("span",{attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])])},function(){var t=this.$createElement,e=this._self._c||t;return e("p",[this._v("Though not supported by all renderers, the optional "),e("code",[this._v("FLOAT")]),this._v(" attribute can be included to create a 32-bit buffer.  This will use up more memory but will store information more accurately between render passes.")])},function(){var t=this.$createElement,e=this._self._c||t;return e("p",[this._v("Further discussion can be found in the "),e("a",{attrs:{href:"primer_chapter_7"}},[this._v("ISF Primer chapter on persistent buffers")]),this._v(" including examples of creating feedback effects and a Conway's Game of Life in GLSL.")])},function(){var t=this.$createElement,e=this._self._c||t;return e("h2",{attrs:{id:"audio-waveforms-and-audio-fft-data"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#audio-waveforms-and-audio-fft-data","aria-hidden":"true"}},[this._v("#")]),this._v(" Audio Waveforms and Audio FFT Data")])},function(){var t=this.$createElement,e=this._self._c||t;return e("p",[this._v("Like with image data, audio inputs are declared in the "),e("code",[this._v("INPUTS")]),this._v(" section of the JSON blob with a special "),e("code",[this._v("TYPE")]),this._v(' set to "audio" or "audioFFT".  The '),e("a",{attrs:{href:"ref_json"}},[this._v("ISF JSON Reference")]),this._v(" contains detailed information about the format in which this data is packed and available optional attributes.")])},function(){var t=this.$createElement,e=this._self._c||t;return e("p",[this._v('From the "ISF tests+tutorials" is this simple audio visualizer shader.  In addition to the declared '),e("code",[this._v("waveImage")]),this._v(" audio input is an options for setting the wave size and output display style called "),e("code",[this._v("waveSize")]),this._v(".")])},function(){var t=this,e=t.$createElement,a=t._self._c||e;return a("div",{staticClass:"language-glsl extra-class"},[a("pre",{pre:!0,attrs:{class:"language-glsl"}},[a("code",[a("span",{attrs:{class:"token comment"}},[t._v('/*\n{\n  "CATEGORIES" : [\n    "Generator"\n  ],\n  "DESCRIPTION" : "Visualizes an audio waveform image",\n  "INPUTS" : [\n    {\n      "NAME" : "waveImage",\n      "TYPE" : "audio"\n    },\n    {\n      "NAME" : "waveSize",\n      "TYPE" : "float",\n      "MAX" : 0.5,\n      "DEFAULT" : 0.05,\n      "MIN" : 0\n    }\n  ],\n  "CREDIT" : "by VIDVOX"\n}\n*/')]),t._v("\n\n"),a("span",{attrs:{class:"token keyword"}},[t._v("void")]),t._v(" "),a("span",{attrs:{class:"token function"}},[t._v("main")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n\t"),a("span",{attrs:{class:"token comment"}},[t._v("//\tjust grab the first audio channel here")]),t._v("\n\t"),a("span",{attrs:{class:"token keyword"}},[t._v("float")]),t._v("\t\tchannel "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{attrs:{class:"token number"}},[t._v("0.0")]),a("span",{attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\t\n\t"),a("span",{attrs:{class:"token comment"}},[t._v("//\tget the location of this pixel")]),t._v("\n\t"),a("span",{attrs:{class:"token keyword"}},[t._v("vec2")]),t._v("\t\tloc "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" isf_FragNormCoord"),a("span",{attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\t\n\t"),a("span",{attrs:{class:"token comment"}},[t._v("//\tthough not needed here, note the IMG_SIZE function can be used to get the dimensions of the audio image")]),t._v("\n\t"),a("span",{attrs:{class:"token comment"}},[t._v("//vec2\t\taudioImgSize = IMG_SIZE(waveImage);")]),t._v("\n\t\n\t"),a("span",{attrs:{class:"token keyword"}},[t._v("vec2")]),t._v("\t\twaveLoc "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{attrs:{class:"token keyword"}},[t._v("vec2")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("loc"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("x"),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v("channel"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\t"),a("span",{attrs:{class:"token keyword"}},[t._v("vec4")]),t._v("\t\twave "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{attrs:{class:"token function"}},[t._v("IMG_NORM_PIXEL")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("waveImage"),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" waveLoc"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\t"),a("span",{attrs:{class:"token keyword"}},[t._v("vec4")]),t._v("\t\twaveAdd "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{attrs:{class:"token number"}},[t._v("1.0")]),t._v(" "),a("span",{attrs:{class:"token operator"}},[t._v("-")]),t._v(" "),a("span",{attrs:{class:"token function"}},[t._v("smoothstep")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{attrs:{class:"token number"}},[t._v("0.0")]),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" waveSize"),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{attrs:{class:"token function"}},[t._v("abs")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("wave "),a("span",{attrs:{class:"token operator"}},[t._v("-")]),t._v(" loc"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("y"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\tgl_FragColor "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" waveAdd"),a("span",{attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),a("span",{attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])])},function(){var t=this.$createElement,e=this._self._c||t;return e("p",[this._v("To pass audio data into shaders, the audio samples are converted into pixel information and packed into an image.  This image is then passed into the shader like any other.  The "),e("code",[this._v("IMG_SIZE()")]),this._v(" function can be used to get the dimensions.  The the y-axis representing individual channels and x-axis contains the raw audio samples for each channel.  From here, the "),e("code",[this._v("IMG_NORM_PIXEL()")]),this._v(" or "),e("code",[this._v("IMG_PIXEL()")]),this._v(" functions can be used to read the sample data.")])},function(){var t=this.$createElement,e=this._self._c||t;return e("p",[this._v("Further discussion and examples can be found in the "),e("a",{attrs:{href:"primer_chapter_8"}},[this._v("ISF Primer chapter on working with audio and audio FFTs")]),this._v(".")])},function(){var t=this.$createElement,e=this._self._c||t;return e("h2",{attrs:{id:"converting-non-isf-glsl-shaders-to-isf"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#converting-non-isf-glsl-shaders-to-isf","aria-hidden":"true"}},[this._v("#")]),this._v(" Converting Non-ISF GLSL Shaders to ISF")])},function(){var t=this.$createElement,e=this._self._c||t;return e("p",[this._v("For example, if you are coming from an environment like The Book of Shaders or Shader Toy, the variable that they use for the time in seconds might be something like "),e("code",[this._v("u_time")]),this._v(" or "),e("code",[this._v("iTime")]),this._v(" and you would simply need to change those to "),e("code",[this._v("TIME")]),this._v(" to work in ISF.")])},function(){var t=this,e=t.$createElement,a=t._self._c||e;return a("ul",[a("li",[t._v("You should probably replace any calls in your shader to "),a("code",[t._v("texture2D()")]),t._v(" or "),a("code",[t._v("texture2DRect()")]),t._v(" with "),a("code",[t._v("IMG_NORM_PIXEL()")]),t._v(" or "),a("code",[t._v("IMG_PIXEL()")]),t._v(", respectively. Images in ISF- inputs, persistent buffers, etc- can be accessed by either "),a("code",[t._v("IMG_NORM_PIXEL()")]),t._v(" or "),a("code",[t._v("IMG_PIXEL()")]),t._v(", depending on whether you want to use normalized or non-normalized coordinates to access the colors of the image. If your shader isn't using these- if it's using "),a("code",[t._v("texture2D()")]),t._v(" or "),a("code",[t._v("texture2DRect()")]),t._v("- it won't compile if the host application tries to send it a different type of texture.")]),t._v(" "),a("li",[t._v("If the shader you are converting makes use of any custom uniform variable declarations for receiving information from a host application, replace these with elements in the "),a("code",[t._v("INPUTS")]),t._v(" section of your JSON blob.")]),t._v(" "),a("li",[t._v("Many shaders pass in the resolution of the image being rendered (knowing where the fragment being evaluated is located within the output image is frequently useful). By default, ISF automatically declares a uniform vec2 named "),a("code",[t._v("RENDERSIZE")]),t._v(" which is passed the dimensions of the image being rendered.")]),t._v(" "),a("li",[t._v("If the shader you're converting requires a time value, note that the uniform float "),a("code",[t._v("TIME")]),t._v(" is declared, and passed the duration (in seconds) which the shader's been runing when the shader's rendered.")]),t._v(" "),a("li",[t._v("Many shaders don't use (or even acknowledge) the alpha channel of the image being rendered. There's nothing wrong with this- but when the shader's loaded in an application that uses the alpha channel, the output of the shader can look bizarre and unpredictable (though it usually involves something being darker than it should be). If you run into this, try setting gl_FragColor.a to 1.0 at the end of your shader.")]),t._v(" "),a("li",[a("code",[t._v("gl_FragCoord.xy")]),t._v(" contains the coordinates of the fragment being evaluated. "),a("code",[t._v("isf_FragNormCoord.xy")]),t._v(" contains the normalized coordinates of the fragment being evaluated.")]),t._v(" "),a("li",[t._v("While ISF files are fragment shaders, and the host environment automatically generates a vertex shader, you can use your own vertex shader if you'd like. If you go this route, your vertex shader should have the same base name as your ISF file (just use the extension .vs), and the first thing you do in your vertex shader's main function is call "),a("code",[t._v("isf_vertShaderInit();")]),t._v(".")]),t._v(" "),a("li",[t._v("If the shader you're converting requires imported graphic resources, note that the ISF format defines the ability to import image files by adding objects to your JSON dict under the "),a("code",[t._v("IMPORTED")]),t._v(" key. The imported images are accessed via the usual "),a("code",[t._v("IMG_PIXEL()")]),t._v(" or "),a("code",[t._v("IMG_NORM_PIXEL()")]),t._v(" methods. Details on how to do this are listed in the full specification and ISF Reference Pages.")]),t._v(" "),a("li",[t._v('If your texture doesn\'t look right, make sure your texture coordinates are ranged properly (textures are typically "clamped" by the host implementation, if you specify an out-of-range texture coordinate it may look funny).')])])},function(){var t=this.$createElement,e=this._self._c||t;return e("p",[this._v("Further discussion and examples can be found in the "),e("a",{attrs:{href:"primer_chapter_9"}},[this._v("ISF Primer chapter on adapting existing GLSL code to the ISF specification")]),this._v(".")])},function(){var t=this.$createElement,e=this._self._c||t;return e("h2",{attrs:{id:"next-steps"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#next-steps","aria-hidden":"true"}},[this._v("#")]),this._v(" Next Steps")])},function(){var t=this.$createElement,e=this._self._c||t;return e("li",[this._v("Read the "),e("a",{attrs:{href:"primer_index"}},[this._v("ISF Primer")]),this._v(" for further discussion and examples of many of the topics on this page.  It also includes lessons covering some of the basics of GLSL programming and how to take advantage of commonly used techniques.")])},function(){var t=this.$createElement,e=this._self._c||t;return e("li",[this._v("The "),e("a",{attrs:{href:"ref_index"}},[this._v("ISF Reference Pages")]),this._v(" are a useful resource for quickly finding information about automatically declared uniforms, built-in functions and other related materials.")])}],!1,null,null,null);n.options.__file="quickstart.md";e.default=n.exports}}]);