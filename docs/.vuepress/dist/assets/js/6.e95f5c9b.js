(window.webpackJsonp=window.webpackJsonp||[]).push([[6],{165:function(e,t,a){"use strict";a.r(t);var o=a(0),n=Object(o.a)({},function(){this.$createElement;this._self._c;return this._m(0)},[function(){var e=this,t=e.$createElement,a=e._self._c||t;return a("div",{staticClass:"content"},[a("h1",{attrs:{id:"the-anatomy-of-an-isf"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#the-anatomy-of-an-isf","aria-hidden":"true"}},[e._v("#")]),e._v(" The anatomy of an ISF")]),e._v(" "),a("p",[e._v("As we discussed in chapter 1, ISF is built on top of GLSL, and as such uses the same file types.  For the first few chapters we'll be dealing with Fragment Shaders that have a '.fs' as a  file extension.  In most cases for generating and processing video you'll only need a fragment shader, however in future chapters we'll also look at another type known as Vertex Shaders (.vs) and how they can be used.")]),e._v(" "),a("p",[e._v("Here we will look at:")]),e._v(" "),a("ul",[a("li",[e._v("The JSON and GLSL portions of an ISF composition.")]),e._v(" "),a("li",[e._v("How to create a shader that generates the same fixed color for every pixel.")]),e._v(" "),a("li",[e._v("How to create a shader that generates the same variable color for every pixel.")]),e._v(" "),a("li",[e._v("How to create a shader that generates a linear gradient between two colors.")]),e._v(" "),a("li",[e._v("The basics of creating an image filter with ISF.")]),e._v(" "),a("li",[e._v("Creating an image filter shader that inverts the colors of an image.")]),e._v(" "),a("li",[e._v("Creating an image filter that moves pixels around, animated over time.")]),e._v(" "),a("li",[e._v("How to include comments in your code to make it easier to understand.")])]),e._v(" "),a("h2",{attrs:{id:"json-and-glsl"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#json-and-glsl","aria-hidden":"true"}},[e._v("#")]),e._v(" JSON and GLSL")]),e._v(" "),a("p",[e._v("Each .fs file that meets the ISF specification is broken up into two sections.  At the top is a JSON blob that contains information used by host applications.  Below that is the GLSL code that is compiled and executed when the plugin is loaded.")]),e._v(" "),a("p",[e._v("All of the code examples in this book that include both a JSON blob and a main() {} function can directly be pasted into a text / code editor, saved as a file with a '.fs' file extension and loaded into software as a generator or filter.")]),e._v(" "),a("h3",{attrs:{id:"json"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#json","aria-hidden":"true"}},[e._v("#")]),e._v(" JSON")]),e._v(" "),a("p",[e._v("JSON, or JavaScript Object Notation is an open-standard file format that uses human-readable text to transmit data objects consisting of attributeâ€“value pairs and array data types.  That's a fancy way of saying that is it a way to write information that is easy for both humans and computers to work with.")]),e._v(" "),a("p",[e._v("An example of a the JSON blob from the 'Test-Float.fs' file:")]),e._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[e._v('/*{\n\t"DESCRIPTION": "demonstrates the use of float-type inputs",\n\t"CREDIT": "by zoidberg",\n\t"ISFVSN": "2.0",\n\t"CATEGORIES": [\n\t\t"TEST-GLSL FX"\n\t],\n\t"INPUTS": [\n\t\t{\n\t\t\t"NAME": "inputImage",\n\t\t\t"TYPE": "image"\n\t\t},\n\t\t{\n\t\t\t"NAME": "level",\n\t\t\t"TYPE": "float",\n\t\t\t"DEFAULT": 0.5,\n\t\t\t"MIN": 0.0,\n\t\t\t"MAX": 1.0\n\t\t}\n\t]\n}*/\n')])])]),a("p",[e._v("As you can see, this text is written in such a way that a human can follow along but also contains enough rigid structure for a computer to parse it.  Within the JSON there are several attributes that each pair with a value that can be used by a host application.")]),e._v(" "),a("p",[e._v("Some of these attributes, such as DESCRIPTION, CREDIT and CATEGORIES, are meta-data tags that can be useful for organizing, searching or describing individual shaders.  Other attributes, such as INPUTS and ISFVSN contain information that help describe the code section below.")]),e._v(" "),a("h3",{attrs:{id:"glsl"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#glsl","aria-hidden":"true"}},[e._v("#")]),e._v(" GLSL")]),e._v(" "),a("p",[e._v('Recalling our discussion from chapter 1, GLSL is also commonly known as the "OpenGL Shading Language" and it has what programmers like to call a C-like syntax because it resembles the C programming language.')]),e._v(" "),a("p",[e._v("With fragment shaders each pixel for the output is preloaded with the same same "),a("code",[e._v("main() {}")]),e._v(" function and its behavior can vary depending on its coordinate position and other input variables that are specific to the individual pixel.")]),e._v(" "),a("p",[e._v('{% include image.html file="/primer/2/primer_2_pixels.jpg" alt="Rendering a 8x8 pixel grid" caption="Fragment Shaders render the same main() {} function for each pixel" %}')]),e._v(" "),a("p",[e._v("This is often a different way of thinking about graphical programming or visual design than many people are accustomed to, but makes sense when you consider the parallel processing power of the GPU.  Rather than write a complex program that needs to step through each coordinate, these smaller micro-programs can be executed on each individual pixel at the same time.")]),e._v(" "),a("p",[e._v("Within a fragment shader meeting the ISF specification, GLSL code is placed in the bottom section of the document.  For the most part, standard shader code can be used, however there are a few small differences with a few functions to help with cross-platform compatibility.")]),e._v(" "),a("p",[e._v("An example of a the GLSL from the 'Test-Float.fs' file:")]),e._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[e._v("void main()\n{\n\tvec4\t\tsrcPixel = IMG_THIS_PIXEL(inputImage);\n\tfloat\t\tluma = (srcPixel.r+srcPixel.g+srcPixel.b)/3.0;\n\tvec4\t\tdstPixel = (luma>level) ? srcPixel : vec4(0,0,0,1);\n\tgl_FragColor = dstPixel;\n}\n")])])]),a("p",[e._v("Here we can see the basics of an image filter where pixels below a certain brightness level are set to black.  Let's look a little closer at the lines of code involved here:")]),e._v(" "),a("ul",[a("li",[e._v("void main() - This declares the main function; each shader must have this, as it is called from the host application when the shader is rendered.")]),e._v(" "),a("li",[e._v("vec4 srcPixel = IMG_THIS_PIXEL(inputImage); - This creates a variable of type vec4 (a vector containing four floating point numbers) and uses the IMG_THIS_PIXEL function to get the color for the pixel that this code will execute on.")]),e._v(" "),a("li",[e._v("float luma = (srcPixel.r+srcPixel.g+srcPixel.b)/3.0; - Calculates the brightness of the RGB channels of the pixels, ignoring the alpha channel.")]),e._v(" "),a("li",[e._v("vec4\t\tdstPixel = (luma>level) ? srcPixel : vec4(0,0,0,1); - Compares the brightness of the pixel to the level specified by the input variable in the JSON blob.")]),e._v(" "),a("li",[e._v("gl_FragColor = dstPixel; - Sets the final color of the pixel to the result from the previous line of code. Each shader must set gl_FragColor to some color value as part of its main function in order to output.")])]),e._v(" "),a("p",[e._v("As you may have noted, two parts of our JSON blob showed up here in the GLSL section, the 'INPUTS' section describes two elements called 'inputImage' and 'level' that are now available as variables in the code.  Going through the attributes we can see that 'level' has a DEFAULT value of 0.5, a MIN value of 0.0 and a MAX value of 1.0 for a variable of type float.")]),e._v(" "),a("h2",{attrs:{id:"generating-images"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#generating-images","aria-hidden":"true"}},[e._v("#")]),e._v(" Generating Images")]),e._v(" "),a("p",[e._v("Now that we've gotten a basic look at how an ISF is put together, we can start on writing our first basic shader.")]),e._v(" "),a("h3",{attrs:{id:"pick-a-color"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#pick-a-color","aria-hidden":"true"}},[e._v("#")]),e._v(" Pick A Color")]),e._v(" "),a("p",[e._v("The most basic ISF example would be something that returns a single color for each pixel.  It might look something like this.")]),e._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[e._v('/*{\n\t"DESCRIPTION": "Every pixel is orange",\n\t"CREDIT": "by VIDVOX",\n\t"ISFVSN": "2.0",\n\t"CATEGORIES": [\n\t\t"TEST-GLSL FX"\n\t]\n}*/\n\nvoid main() {\n\tgl_FragColor = vec4(1.0,0.5,0.0,1.0);\n}\n')])])]),a("h3",{attrs:{id:"add-an-input"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#add-an-input","aria-hidden":"true"}},[e._v("#")]),e._v(" Add an input")]),e._v(" "),a("p",[e._v("Now let's expand this shaders so that instead of rendering a single fixed value we can set the render color based on one provided from a host application.")]),e._v(" "),a("p",[e._v('The ISF specification supports several different types of INPUTS, including image, float, bool, long, color, event, audio, audioFFT and point.  Here we\'ll be adding in a "color" variable which contains an RGBA value.')]),e._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[e._v('/*{\n\t"DESCRIPTION": "Demonstrates the use of color-type image inputs",\n\t"CREDIT": "by VIDVOX",\n\t"ISFVSN": "2.0",\n\t"CATEGORIES": [\n\t\t"TEST-GLSL FX"\n\t],\n\t"INPUTS": [\n\t\t{\n\t\t\t"NAME": "theColor",\n\t\t\t"TYPE": "color",\n\t\t\t"DEFAULT": [\n\t\t\t\t1.0,\n\t\t\t\t0.5,\n\t\t\t\t0.0,\n\t\t\t\t1.0\n\t\t\t]\n\t\t}\n\t]\n}*/\n\nvoid main()\n{\n\tgl_FragColor = theColor;\n}\n')])])]),a("p",[e._v('Just like with our other variables declared in the JSON blob in previous examples, "theColor" can be used in our GLSL code anywhere we\'d use a vec4 we declared locally.')]),e._v(" "),a("h3",{attrs:{id:"varying-based-on-position"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#varying-based-on-position","aria-hidden":"true"}},[e._v("#")]),e._v(" Varying based on position")]),e._v(" "),a("p",[e._v('So far we\'ve examined how to set each pixel in a generator shader to the exact same color.  What if we wanted them to be different based on some criteria?  This is where the "isf_FragNormCoord" and "gl_FragCoord.xy" variables come into play.  Each is a vec2 (a vector that contains two floating point numbers) that contains the xy coordinate of the pixel being rendered.')]),e._v(" "),a("ul",[a("li",[e._v("gl_FragCoord.xy is a standard variable in GLSL shaders and represents the specific integer pixel coordinates of current the pixel.")]),e._v(" "),a("li",[e._v("isf_FragNormCoord is an extension for ISF that contains a normalized (ranged 0 to 1) version of the current pixel coordinate.")]),e._v(" "),a("li",[e._v("RENDERSIZE is another extension for ISF that contains the overall pixel dimensions for the output being rendered.  This tells you the range for the gl_FragCoord.xy variable.")])]),e._v(" "),a("p",[e._v("Let's look how we can create a shader that fades between two colors, varying over the x position (left to right) of the image.")]),e._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[e._v('/*{\n\t"DESCRIPTION": "Creates a linear gradient from one color to another",\n\t"CREDIT": "by VIDVOX",\n\t"ISFVSN": "2.0",\n\t"CATEGORIES": [\n\t\t"TEST-GLSL FX"\n\t],\n\t"INPUTS": [\n\t\t{\n\t\t\t"NAME": "theColor1",\n\t\t\t"TYPE": "color",\n\t\t\t"DEFAULT": [\n\t\t\t\t1.0,\n\t\t\t\t0.5,\n\t\t\t\t0.0,\n\t\t\t\t1.0\n\t\t\t]\n\t\t},\n\t\t{\n\t\t\t"NAME": "theColor2",\n\t\t\t"TYPE": "color",\n\t\t\t"DEFAULT": [\n\t\t\t\t0.0,\n\t\t\t\t0.0,\n\t\t\t\t1.0,\n\t\t\t\t1.0\n\t\t\t]\n\t\t}\n\t]\n}*/\n\nvoid main()\n{\n\tgl_FragColor = mix(theColor1,theColor2,isf_FragNormCoord.x);\n}\n')])])]),a("p",[e._v("Here there isn't much new in our JSON blob other thanÂ we've added a second color variable.  In the GLSL code there are two important details to check out:")]),e._v(" "),a("ul",[a("li",[e._v("We've introduced 'mix' as our first function other than the 'main' function.  The mix function can take two colors and a floating point number from 0.0 to 1.0 as inputs and returns a color that somewhere in between the provided colors based on the provided mix percentage.  GLSL provides many useful "),a("a",{attrs:{href:"ref_functions"}},[e._v("built-in functions")]),e._v(" and you can create your own re-usable functions which can be useful for writing concise code.")]),e._v(" "),a("li",[e._v("As the position of the mix percentage we've entered 'isf_FragNormCoord.x' which tells the shader to use the normalized x position for the current position.  As mentioned above, the normalized value goes from 0.0 on the left to 1.0 on the right side of the texture frame.  To have this displayed as a vertical gradient, you can change this variable to 'isf_FragNormCoord.y'.")])]),e._v(" "),a("h2",{attrs:{id:"processing-images"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#processing-images","aria-hidden":"true"}},[e._v("#")]),e._v(" Processing images")]),e._v(" "),a("p",[e._v("So far we've seen how to use ISF to generate totally new images by returning the desired color for each individual output pixel.  The other big use case for ISF compositions is to take existing pixel color information, process it in some way and then return the result.")]),e._v(" "),a("h3",{attrs:{id:"changing-colors"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#changing-colors","aria-hidden":"true"}},[e._v("#")]),e._v(" Changing colors")]),e._v(" "),a("p",[e._v("For our first example we'll examine one of the most basic standard FX,Â Color Invert.fs, which takes an input pixel and inverts the rgb channels while leaving the alpha channel intact.")]),e._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[e._v('/*{\n\t"DESCRIPTION": "Inverts each pixel",\n\t"CREDIT": "by VIDVOX",\n\t"ISFVSN": "2",\n\t"CATEGORIES": [\n\t\t"Color Effect"\n\t],\n\t"INPUTS": [\n\t\t{\n\t\t\t"NAME": "inputImage",\n\t\t\t"TYPE": "image"\n\t\t}\n\t]\n}*/\n\nvoid main() {\n\tvec4\tsrcPixel = IMG_THIS_PIXEL(inputImage);\n\tgl_FragColor = vec4(1.0-srcPixel.r, 1.0-srcPixel.g, 1.0-srcPixel.b, srcPixel.a);\n}\n')])])]),a("p",[e._v("Make a special note of how here we have one object in our 'INPUTS' array called \"inputImage\" that is of type \"image\" â€“Â this is an important detail in the ISF specification that tells host applications that this file is meant to be used as an 'FX' instead of a generator.")]),e._v(" "),a("p",[e._v("In the code section below the JSON blob, the \"inputImage\" variable is used with a special function called 'IMG_THIS_PIXEL' which returns the color for the corresponding pixel that is being processed.  This value is stored in a vec4 called 'srcPixel'.")]),e._v(" "),a("p",[e._v("If you are already familiar with GLSL, the function 'IMG_THIS_PIXEL' is a one of several functions available in ISF to be used instead of texture2D() and texture2DRect().  For those who are curious, this is further explained in the ISF Specification document.")]),e._v(" "),a("p",[e._v("For the final line of code, gl_FragColor is set to a new color value that is created by subtracting each RGB color channel from 1.0, and leaving the alpha channel intact.  We could also write this final line of code a different way and get the same result:")]),e._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[e._v("gl_FragColor = vec4(1.0-srcPixel.rgb,srcPixel.a);\n")])])]),a("h3",{attrs:{id:"moving-pixels"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#moving-pixels","aria-hidden":"true"}},[e._v("#")]),e._v(" Moving pixels")]),e._v(" "),a("p",[e._v("Another common usage for image processing is changing the positions of pixels.  Like with our previous example of creating a color gradient, for in this shader we will make use of the automatically provided 'isf_FragNormCoord' variable to get the location of the pixel being processed.")]),e._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[e._v('/*{\n\t"DESCRIPTION": "Shift pixels to the left",\n\t"CREDIT": "by VIDVOX",\n\t"ISFVSN": "2.0",\n\t"CATEGORIES": [\n\t\t"TEST-GLSL FX"\n\t],\n\t"INPUTS": [\n\t\t{\n\t\t\t"NAME": "inputImage",\n\t\t\t"TYPE": "image"\n\t\t}\n\t]\n}*/\n\nvoid main() {\n\tvec2\tloc = isf_FragNormCoord;\n\tfloat\tshift = TIME;\n\tloc.x += shift;\n\tloc.x = mod(loc.x,1.0);\n\tgl_FragColor = IMG_NORM_PIXEL(inputImage,loc);\n}\n')])])]),a("p",[e._v('As before we have an "image" titled "inputImage" as part of the \'INPUTS\' array.')]),e._v(" "),a("p",[e._v("To create the shift effect, the isf_FragNormCoord is first stored in a local vec2 variable called \"loc\" which is then adjusted by adding the amount of shift and applying the modulus function to create a wrap at the edge.  Try commenting out the line with the 'mod' call to see the difference.")]),e._v(" "),a("p",[e._v("You may have also noted that we've introduced 'TIME' as a variable in the GLSL code without declaring it in our JSON blob!  Normally this would not work, however 'TIME' is one of a few special variables available in ISF that are automatically available if needed.  In this case the variable always contains the current time, in seconds, since the ISF has begun rendering.  We will look at the other automatic variables in ISF in the next chapter.")]),e._v(" "),a("p",[e._v("Finally we use the 'IMG_NORM_PIXEL' function to get the color of the pixel at the desired location and return it instead of the original pixel.  Since no further processing will be applied there is no need to store this result in its own vec4, we can use it to directly set the gl_FragColor.")]),e._v(" "),a("p",[e._v("If you've been working with C-syntax for some time, you may have noted that we could have written this same code more concisely like this:")]),e._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[e._v("void main() {\n\tgl_FragColor = IMG_NORM_PIXEL(inputImage,vec2(mod(isf_FragNormCoord.x+TIME,1.0),isf_FragNormCoord.y));\n}\n")])])]),a("p",[e._v("However it is not as easy to read for a tutorial lesson like this.  As you write more code, it will be up to you as to whether or not you prefer to optimize your code for legibility by humans or conciseness.")]),e._v(" "),a("h2",{attrs:{id:"commenting-code"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#commenting-code","aria-hidden":"true"}},[e._v("#")]),e._v(" Commenting Code")]),e._v(" "),a("p",[e._v("When writing code, whether for your own personal use or for sharing with others who may want to learn from it, GLSL allows for including lines of text called 'comments' that are ignored when it comes time to run the shader.")]),e._v(" "),a("p",[e._v("In GLSL comments come in two syntaxes that are common to many other languages.")]),e._v(" "),a("ul",[a("li",[e._v("On any line, any text after a "),a("code",[e._v("//")]),e._v(" will be ignored.")]),e._v(" "),a("li",[e._v("Any text that is between an opening "),a("code",[e._v("/*")]),e._v(" and a closing "),a("code",[e._v("*/")]),e._v(" pair will be ignored.")])]),e._v(" "),a("p",[e._v("Note that you can put comments before, after, or directly within your code.")]),e._v(" "),a("p",[e._v("Though comments are not required, it is a generally encouraged practice that you may want to include as part of your workflow.")])])}],!1,null,null,null);n.options.__file="primer_chapter_2.md";t.default=n.exports}}]);