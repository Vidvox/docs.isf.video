{"remainingRequest":"/Users/turner/Projects/new-isf-docs/node_modules/vue-loader/lib/loaders/templateLoader.js??vue-loader-options!/Users/turner/Projects/new-isf-docs/node_modules/cache-loader/dist/cjs.js??ref--1-0!/Users/turner/Projects/new-isf-docs/node_modules/vue-loader/lib/index.js??ref--1-1!/Users/turner/Projects/new-isf-docs/node_modules/vuepress/lib/webpack/markdownLoader.js??ref--1-2!/Users/turner/Projects/new-isf-docs/docs/primer/primer_chapter_7.md?vue&type=template&id=266665ae&","dependencies":[{"path":"/Users/turner/Projects/new-isf-docs/docs/primer/primer_chapter_7.md","mtime":1541952936489},{"path":"/Users/turner/Projects/new-isf-docs/node_modules/cache-loader/dist/cjs.js","mtime":1542141147539},{"path":"/Users/turner/Projects/new-isf-docs/node_modules/vue-loader/lib/loaders/templateLoader.js","mtime":1542141147910},{"path":"/Users/turner/Projects/new-isf-docs/node_modules/cache-loader/dist/cjs.js","mtime":1542141147539},{"path":"/Users/turner/Projects/new-isf-docs/node_modules/vue-loader/lib/index.js","mtime":1542141147910},{"path":"/Users/turner/Projects/new-isf-docs/node_modules/vuepress/lib/webpack/markdownLoader.js","mtime":1542141152593}],"contextDependencies":[],"result":["var render = function() {\n  var _vm = this\n  var _h = _vm.$createElement\n  var _c = _vm._self._c || _h\n  return _c(\"div\", { staticClass: \"content\" }, [\n    _vm._m(0),\n    _vm._v(\" \"),\n    _c(\"p\", [\n      _vm._v(\n        \"Two extremely powerful concepts that ISF adds on to GLSL are the ability to retain image information between render passes (persistent buffers) and creating compound shaders that have multiple rendering stages (multi-pass shaders) at potentially varying sizes.\"\n      )\n    ]),\n    _vm._v(\" \"),\n    _c(\"p\", [_vm._v(\"In this chapter we'll look at:\")]),\n    _vm._v(\" \"),\n    _vm._m(1),\n    _vm._v(\" \"),\n    _vm._m(2),\n    _vm._v(\" \"),\n    _c(\"p\", [\n      _vm._v(\n        'ISF files can define persistent buffers.  These buffers are images (GL textures) that stay with the ISF file for as long as it exists. This is useful if you want to \"build up\" an image over time- you can repeatedly query and update the contents of persistent buffers by rendering into them- or if you want to perform calculations across the entire image, storing the results somewhere for later evaluation. Further details on exactly how to do this are in the full '\n      ),\n      _c(\n        \"a\",\n        {\n          attrs: {\n            href: \"https://github.com/mrRay/ISF_Spec/\",\n            target: \"_blank\",\n            rel: \"noopener noreferrer\"\n          }\n        },\n        [_vm._v(\"ISF Specification Page\"), _c(\"OutboundLink\")],\n        1\n      ),\n      _vm._v(\".\")\n    ]),\n    _vm._v(\" \"),\n    _vm._m(3),\n    _vm._m(4),\n    _vm._v(\" \"),\n    _vm._m(5),\n    _vm._v(\" \"),\n    _c(\"p\", [\n      _vm._v(\n        \"For this ISF we have a single render pass, that is persistent and stores floating point values.\"\n      )\n    ]),\n    _vm._v(\" \"),\n    _vm._m(6),\n    _vm._v(\" \"),\n    _vm._m(7),\n    _vm._v(\" \"),\n    _vm._m(8),\n    _vm._v(\" \"),\n    _c(\"p\", [\n      _vm._v(\n        \"One of the most common usages of persistent buffers is creating video feedback loops.  This is a process that goes back to the days of analog video and the same idea can be done digitally.  The above shader is an example of of this technique: By blending the previous pixel with the current frame, the visual effect of a feedback style motion blur is created.  Adding in additional functionality to this shader such as zooming, rotating, inverting, applying convolution kernels to blur / sharpen can create all kinds of interesting results.\"\n      )\n    ]),\n    _vm._v(\" \"),\n    _c(\"p\", [\n      _vm._v(\n        \"Here is an example of how to modify the example to include an invert stage:\"\n      )\n    ]),\n    _vm._v(\" \"),\n    _vm._m(9),\n    _vm._m(10),\n    _vm._v(\" \"),\n    _vm._m(11),\n    _vm._v(\" \"),\n    _vm._m(12),\n    _vm._v(\" \"),\n    _vm._m(13),\n    _vm._m(14),\n    _vm._v(\" \"),\n    _vm._m(15),\n    _vm._v(\" \"),\n    _vm._m(16),\n    _vm._v(\" \"),\n    _vm._m(17),\n    _vm._v(\" \"),\n    _vm._m(18),\n    _vm._v(\" \"),\n    _c(\"p\", [\n      _vm._v(\n        \"As you may have noted in the previous chapter on convolution, a basic 3x3 kernel does not blur an image very much, unless you are very zoomed in.  One way to address this was to use larger kernel sizes that average together even more neighboring pixels on each pass.  The downside of using large kernels is that they are computationally very costly.\"\n      )\n    ]),\n    _vm._v(\" \"),\n    _c(\"p\", [\n      _vm._v(\n        \"Another way to create stronger blurring effects is to re-apply the blur multiple times in a single effect.\"\n      )\n    ]),\n    _vm._v(\" \"),\n    _c(\"p\", [\n      _vm._v(\n        \"Like with most things in GLSL, there are several ways you can go about writing a multi-pass blur and you can find several advanced examples on the ISF Sharing Site in the Blurs category.  In this section we will look at one of the more basic examples called Soft Blur.fs which is a 3-pass blur shader.\"\n      )\n    ]),\n    _vm._v(\" \"),\n    _c(\"p\", [\n      _vm._v(\n        \"First we will write the vertex shader.  This is exactly the same as the .vs we used for the basic convolution shaders in the previous chapter.\"\n      )\n    ]),\n    _vm._v(\" \"),\n    _vm._m(19),\n    _c(\"p\", [_vm._v(\"Next we have the fragment shader:\")]),\n    _vm._v(\" \"),\n    _vm._m(20),\n    _vm._m(21),\n    _vm._v(\" \"),\n    _vm._m(22),\n    _vm._v(\" \"),\n    _vm._m(23),\n    _vm._v(\" \"),\n    _vm._m(24),\n    _vm._v(\" \"),\n    _c(\"p\", [\n      _vm._v(\n        \"In computing simulation, one of the most famous algorithms is known as Conway's Game of Life.  Game of Life is a cellular automaton devised by the British mathematician John Horton Conway in 1970.  Though it is called a game, there aren't any players - the board starts with a random or preconfigured state and then evolves from there.\"\n      )\n    ]),\n    _vm._v(\" \"),\n    _c(\"p\", [\n      _vm._v(\"The \"),\n      _c(\n        \"a\",\n        {\n          attrs: {\n            href: \"https://en.wikipedia.org/wiki/Conway's_Game_of_Life\",\n            target: \"_blank\",\n            rel: \"noopener noreferrer\"\n          }\n        },\n        [_vm._v(\"Wikipedia page on Game of Life\"), _c(\"OutboundLink\")],\n        1\n      ),\n      _vm._v(\" describes the rules as such:\")\n    ]),\n    _vm._v(\" \"),\n    _vm._m(25),\n    _vm._v(\" \"),\n    _c(\"p\", [\n      _vm._v(\n        \"The idea of comparing a cell to its surround eight neighbors sounds an awful lot like what we have been doing with our convolution filters.  The only difference here is instead of using a kernel to process an incoming image, we'll need to start with some initial state and then iterate on that.\"\n      )\n    ]),\n    _vm._v(\" \"),\n    _vm._m(26),\n    _vm._v(\" \"),\n    _vm._m(27),\n    _vm._m(28),\n    _vm._v(\" \"),\n    _vm._m(29),\n    _vm._v(\" \"),\n    _vm._m(30),\n    _vm._v(\" \"),\n    _c(\"p\", [\n      _vm._v(\n        \"This simple set of rules creates a wide variety of different outcomes and the basic concept of cellular automaton can be used as a starting point for creating evolving behaviors within other shaders.  Recall that with ISF, you can make Game of Life just the first of multiple render passes that use the state information as part of more complex generators or effects.\"\n      )\n    ]),\n    _vm._v(\" \"),\n    _c(\"p\", [\n      _vm._v(\n        \"The Game of Life shader itself can be remixed in various interesting ways.  Here are a few challenges:\"\n      )\n    ]),\n    _vm._v(\" \"),\n    _vm._m(31)\n  ])\n}\nvar staticRenderFns = [\n  function() {\n    var _vm = this\n    var _h = _vm.$createElement\n    var _c = _vm._self._c || _h\n    return _c(\n      \"h1\",\n      { attrs: { id: \"multi-pass-shaders-and-persistent-buffers-in-isf\" } },\n      [\n        _c(\n          \"a\",\n          {\n            staticClass: \"header-anchor\",\n            attrs: {\n              href: \"#multi-pass-shaders-and-persistent-buffers-in-isf\",\n              \"aria-hidden\": \"true\"\n            }\n          },\n          [_vm._v(\"#\")]\n        ),\n        _vm._v(\" Multi-Pass Shaders and Persistent Buffers in ISF\")\n      ]\n    )\n  },\n  function() {\n    var _vm = this\n    var _h = _vm.$createElement\n    var _c = _vm._self._c || _h\n    return _c(\"ul\", [\n      _c(\"li\", [_vm._v(\"How to set up a persistent buffer.\")]),\n      _vm._v(\" \"),\n      _c(\"li\", [\n        _vm._v(\n          \"Discuss creating feedback style effects with persistent buffers.\"\n        )\n      ]),\n      _vm._v(\" \"),\n      _c(\"li\", [_vm._v(\"How to set up multiple render passes.\")]),\n      _vm._v(\" \"),\n      _c(\"li\", [\n        _vm._v(\"Discuss creating a deep blur using multiple render passes.\")\n      ]),\n      _vm._v(\" \"),\n      _c(\"li\", [\n        _vm._v(\n          \"How to make a Conway's Game of Life generator using a persistent buffer.\"\n        )\n      ])\n    ])\n  },\n  function() {\n    var _vm = this\n    var _h = _vm.$createElement\n    var _c = _vm._self._c || _h\n    return _c(\"h2\", { attrs: { id: \"persistent-buffers\" } }, [\n      _c(\n        \"a\",\n        {\n          staticClass: \"header-anchor\",\n          attrs: { href: \"#persistent-buffers\", \"aria-hidden\": \"true\" }\n        },\n        [_vm._v(\"#\")]\n      ),\n      _vm._v(\" Persistent Buffers\")\n    ])\n  },\n  function() {\n    var _vm = this\n    var _h = _vm.$createElement\n    var _c = _vm._self._c || _h\n    return _c(\"div\", { staticClass: \"language- extra-class\" }, [\n      _c(\"pre\", { pre: true, attrs: { class: \"language-text\" } }, [\n        _c(\"code\", [\n          _vm._v(\n            '/*{\\n\\t\"DESCRIPTION\": \"demonstrates the use of a persistent buffer to create a motion-blur type effect. also demonstrates the simplest use of steps: a one-step rendering pass\",\\n\\t\"CREDIT\": \"by zoidberg\",\\n\\t\"ISFVSN\": \"2.0\",\\n\\t\"CATEGORIES\": [\\n\\t\\t\"TEST-GLSL FX\"\\n\\t],\\n\\t\"INPUTS\": [\\n\\t\\t{\\n\\t\\t\\t\"NAME\": \"inputImage\",\\n\\t\\t\\t\"TYPE\": \"image\"\\n\\t\\t},\\n\\t\\t{\\n\\t\\t\\t\"NAME\": \"blurAmount\",\\n\\t\\t\\t\"TYPE\": \"float\"\\n\\t\\t}\\n\\t],\\n\\t\"PASSES\": [\\n\\t\\t{\\n\\t\\t\\t\"TARGET\": \"bufferVariableNameA\",\\n\\t\\t\\t\"PERSISTENT\": true,\\n\\t\\t\\t\"FLOAT\": true\\n\\t\\t}\\n\\t]\\n\\t\\n}*/\\n\\nvoid main()\\n{\\n\\tvec4\\t\\tfreshPixel = IMG_THIS_PIXEL(inputImage);\\n\\tvec4\\t\\tstalePixel = IMG_THIS_PIXEL(bufferVariableNameA);\\n\\tgl_FragColor = mix(freshPixel,stalePixel,blurAmount);\\n}\\n'\n          )\n        ])\n      ])\n    ])\n  },\n  function() {\n    var _vm = this\n    var _h = _vm.$createElement\n    var _c = _vm._self._c || _h\n    return _c(\"p\", [\n      _vm._v(\n        \"In this simple example we have added a new section to our JSON blob called \"\n      ),\n      _c(\"code\", [_vm._v(\"PASSES\")]),\n      _vm._v(\n        \" which is used to describe each render pass of the shader.  Here you can set the options for each pass.\"\n      )\n    ])\n  },\n  function() {\n    var _vm = this\n    var _h = _vm.$createElement\n    var _c = _vm._self._c || _h\n    return _c(\"ul\", [\n      _c(\"li\", [\n        _vm._v(\"The \"),\n        _c(\"code\", [_vm._v(\"TARGET\")]),\n        _vm._v(\n          \" attribute is used to set the name by which this render pass will be referred to in the code section.  This will be available as an \"\n        ),\n        _c(\"code\", [_vm._v(\"IMAGE\")]),\n        _vm._v(\" type.\")\n      ]),\n      _vm._v(\" \"),\n      _c(\"li\", [\n        _vm._v(\"For each buffer that you wish to retain between passes, the \"),\n        _c(\"code\", [_vm._v(\"PERSISTENT\")]),\n        _vm._v(\" can be set to \"),\n        _c(\"code\", [_vm._v(\"true\")]),\n        _vm._v(\".\")\n      ]),\n      _vm._v(\" \"),\n      _c(\"li\", [\n        _vm._v(\n          \"If you wish to have the value stored as a 32-bit floating point value the additional \"\n        ),\n        _c(\"code\", [_vm._v(\"FLOAT\")]),\n        _vm._v(\" attribute can be included and set to \"),\n        _c(\"code\", [_vm._v(\"true\")]),\n        _vm._v(\n          \".  Using 32-bit textures will use up more memory, but in some cases can be extremely useful.\"\n        )\n      ])\n    ])\n  },\n  function() {\n    var _vm = this\n    var _h = _vm.$createElement\n    var _c = _vm._self._c || _h\n    return _c(\"p\", [\n      _vm._v(\"In the code section we refer to the image \"),\n      _c(\"code\", [_vm._v(\"bufferVariableNameA\")]),\n      _vm._v(\", which holds the output from the previous frame.\")\n    ])\n  },\n  function() {\n    var _vm = this\n    var _h = _vm.$createElement\n    var _c = _vm._self._c || _h\n    return _c(\"p\", [\n      _vm._v(\"When the \"),\n      _c(\"code\", [_vm._v(\"PASSES\")]),\n      _vm._v(\n        \" section is left out, as in our previous examples, it is presumed that the shader includes a single render pass and that the output is not stored in memory to be used later on.\"\n      )\n    ])\n  },\n  function() {\n    var _vm = this\n    var _h = _vm.$createElement\n    var _c = _vm._self._c || _h\n    return _c(\"h3\", { attrs: { id: \"video-feedback\" } }, [\n      _c(\n        \"a\",\n        {\n          staticClass: \"header-anchor\",\n          attrs: { href: \"#video-feedback\", \"aria-hidden\": \"true\" }\n        },\n        [_vm._v(\"#\")]\n      ),\n      _vm._v(\" Video Feedback\")\n    ])\n  },\n  function() {\n    var _vm = this\n    var _h = _vm.$createElement\n    var _c = _vm._self._c || _h\n    return _c(\"div\", { staticClass: \"language- extra-class\" }, [\n      _c(\"pre\", { pre: true, attrs: { class: \"language-text\" } }, [\n        _c(\"code\", [\n          _vm._v(\n            '/*{\\n\\t\"DESCRIPTION\": \"creates a simple inverting feedback effect\",\\n\\t\"CREDIT\": \"by VIDVOX\",\\n\\t\"ISFVSN\": \"2.0\",\\n\\t\"CATEGORIES\": [\\n\\t\\t\"TEST-GLSL FX\"\\n\\t],\\n\\t\"INPUTS\": [\\n\\t\\t{\\n\\t\\t\\t\"NAME\": \"inputImage\",\\n\\t\\t\\t\"TYPE\": \"image\"\\n\\t\\t},\\n\\t\\t{\\n\\t\\t\\t\"NAME\": \"blurAmount\",\\n\\t\\t\\t\"TYPE\": \"float\"\\n\\t\\t}\\n\\t],\\n\\t\"PASSES\": [\\n\\t\\t{\\n\\t\\t\\t\"TARGET\": \"bufferVariableNameA\",\\n\\t\\t\\t\"PERSISTENT\": true,\\n\\t\\t\\t\"FLOAT\": true\\n\\t\\t}\\n\\t]\\n\\t\\n}*/\\n\\nvoid main()\\n{\\n\\tvec4\\t\\tfreshPixel = IMG_THIS_PIXEL(inputImage);\\n\\tvec4\\t\\tstalePixel = IMG_THIS_PIXEL(bufferVariableNameA);\\n\\tstalePixel.rgb = 1.0 - stalePixel.rgb;\\n\\tgl_FragColor = mix(freshPixel,stalePixel,blurAmount);\\n}\\n'\n          )\n        ])\n      ])\n    ])\n  },\n  function() {\n    var _vm = this\n    var _h = _vm.$createElement\n    var _c = _vm._self._c || _h\n    return _c(\"p\", [\n      _vm._v(\n        \"Here we have simply added the line that on each pass inverts the rgb of the \"\n      ),\n      _c(\"code\", [_vm._v(\"stalePixel\")]),\n      _vm._v(\n        \".  As a challenge, try adding the rotate or blurring sample code from previous chapters and apply them to the \"\n      ),\n      _c(\"code\", [_vm._v(\"stalePixel\")]),\n      _vm._v(\" before the \"),\n      _c(\"code\", [_vm._v(\"mix\")]),\n      _vm._v(\" function is called.\")\n    ])\n  },\n  function() {\n    var _vm = this\n    var _h = _vm.$createElement\n    var _c = _vm._self._c || _h\n    return _c(\"h2\", { attrs: { id: \"multi-pass-shaders\" } }, [\n      _c(\n        \"a\",\n        {\n          staticClass: \"header-anchor\",\n          attrs: { href: \"#multi-pass-shaders\", \"aria-hidden\": \"true\" }\n        },\n        [_vm._v(\"#\")]\n      ),\n      _vm._v(\" Multi-Pass Shaders\")\n    ])\n  },\n  function() {\n    var _vm = this\n    var _h = _vm.$createElement\n    var _c = _vm._self._c || _h\n    return _c(\"p\", [\n      _vm._v(\n        \"The ISF file format defines the ability to execute a shader multiple times in the process of rendering a frame for output- each time the shader's executed (each pass), the uniform int variable \"\n      ),\n      _c(\"code\", [_vm._v(\"PASSINDEX\")]),\n      _vm._v(\n        \" is incremented. Details on how to accomplish this are described below in the spec, but the basic process involves adding an array of dicts to the \"\n      ),\n      _c(\"code\", [_vm._v(\"PASSES\")]),\n      _vm._v(\" key in your top-level JSON dict. Each dict in the \"),\n      _c(\"code\", [_vm._v(\"PASSES\")]),\n      _vm._v(\n        \" array describes a different rendering pass- the ISF host will automatically create buffers to render into, and those buffers (and therefore the results of those rendering passes) can be accessed like any other buffer/input image/imported image (you can render to a texture in one pass, and then read that texture back in and render something else in another pass).  The dicts in \"\n      ),\n      _c(\"code\", [_vm._v(\"PASSES\")]),\n      _vm._v(\n        \" recognize a number of different keys to specify different properties of the rendering passes- more details are in the spec below.\"\n      )\n    ])\n  },\n  function() {\n    var _vm = this\n    var _h = _vm.$createElement\n    var _c = _vm._self._c || _h\n    return _c(\"div\", { staticClass: \"language- extra-class\" }, [\n      _c(\"pre\", { pre: true, attrs: { class: \"language-text\" } }, [\n        _c(\"code\", [\n          _vm._v(\n            '/*{\\n\\t\"DESCRIPTION\": \"demonstrates the use of two-pass rendering- the first pass renders to a persistent buffer which is substantially smaller than the res of the image being drawn.  the second pass renders at the default requested size and scales up the image from the first pass\",\\n\\t\"CREDIT\": \"by zoidberg\",\\n\\t\"ISFVSN\": \"2.0\",\\n\\t\"CATEGORIES\": [\\n\\t\\t\"TEST-GLSL FX\"\\n\\t],\\n\\t\"INPUTS\": [\\n\\t\\t{\\n\\t\\t\\t\"NAME\": \"inputImage\",\\n\\t\\t\\t\"TYPE\": \"image\"\\n\\t\\t}\\n\\t],\\n\\t\"PASSES\": [\\n\\t\\t{\\n\\t\\t\\t\"TARGET\":\"bufferVariableNameA\",\\n\\t\\t\\t\"PERSISTENT\": true,\\n\\t\\t\\t\"WIDTH\": \"$WIDTH/16.0\",\\n\\t\\t\\t\"HEIGHT\": \"$HEIGHT/16.0\"\\n\\t\\t},\\n\\t\\t{\\n\\t\\t\\n\\t\\t}\\n\\t]\\n\\t\\n}*/\\n\\nvoid main()\\n{\\n\\t//\\tfirst pass: read the \"inputImage\"- remember, we\\'re drawing to the persistent buffer \"bufferVariableNameA\" on the first pass\\n\\tif (PASSINDEX == 0)\\t{\\n\\t\\tgl_FragColor = IMG_THIS_NORM_PIXEL(inputImage);\\n\\t}\\n\\t//\\tsecond pass: read from \"bufferVariableNameA\".  output looks chunky and low-res.\\n\\telse if (PASSINDEX == 1)\\t{\\n\\t\\tgl_FragColor = IMG_THIS_NORM_PIXEL(bufferVariableNameA);\\n\\t}\\n}\\n'\n          )\n        ])\n      ])\n    ])\n  },\n  function() {\n    var _vm = this\n    var _h = _vm.$createElement\n    var _c = _vm._self._c || _h\n    return _c(\"p\", [\n      _vm._v(\"Like in our previous example, we had added the new \"),\n      _c(\"code\", [_vm._v(\"PASSES\")]),\n      _vm._v(\n        \" section to the JSON blob.  This time there are two entries – the first is persistent and has a target name, the second contains no attributes.\"\n      )\n    ])\n  },\n  function() {\n    var _vm = this\n    var _h = _vm.$createElement\n    var _c = _vm._self._c || _h\n    return _c(\"p\", [\n      _vm._v(\"The first pass also has two new attributes: \"),\n      _c(\"code\", [_vm._v(\"WIDTH\")]),\n      _vm._v(\" and \"),\n      _c(\"code\", [_vm._v(\"HEIGHT\")]),\n      _vm._v(\n        \" which can be used to resize the image before it is provided to the shader.  These attributes can be set to specific values, or you can enter in simple mathematically equations that allow them to vary depending on the actual width and height of the incoming image.  Declared uniform variables can also be used in these equations.  In this particular case the buffer will be resized to 1/16th its original width and height.\"\n      )\n    ])\n  },\n  function() {\n    var _vm = this\n    var _h = _vm.$createElement\n    var _c = _vm._self._c || _h\n    return _c(\"p\", [\n      _vm._v(\"In the code section itself, the new variable \"),\n      _c(\"code\", [_vm._v(\"PASSINDEX\")]),\n      _vm._v(\" is also used.  The \"),\n      _c(\"code\", [_vm._v(\"PASSINDEX\")]),\n      _vm._v(\n        \" is a special automatically created uniform variable that is used to tell the main() {} function which rendering pass is currently being executed.  This allows you to write compound shaders that perform different operations on each pass.\"\n      )\n    ])\n  },\n  function() {\n    var _vm = this\n    var _h = _vm.$createElement\n    var _c = _vm._self._c || _h\n    return _c(\"ul\", [\n      _c(\"li\", [\n        _vm._v(\"The \"),\n        _c(\"code\", [_vm._v(\"PASSINDEX\")]),\n        _vm._v(\n          \" starts at 0 and increments on each pass.  So the first pass is 0, the second pass is 1, the third is 2, and so on.\"\n        )\n      ]),\n      _vm._v(\" \"),\n      _c(\"li\", [\n        _vm._v(\"Because it is a uniform, the \"),\n        _c(\"code\", [_vm._v(\"PASSINDEX\")]),\n        _vm._v(\n          \" variable is available to both the fragment and vertex shaders.\"\n        )\n      ])\n    ])\n  },\n  function() {\n    var _vm = this\n    var _h = _vm.$createElement\n    var _c = _vm._self._c || _h\n    return _c(\"h3\", { attrs: { id: \"creating-a-multi-pass-blur-effect\" } }, [\n      _c(\n        \"a\",\n        {\n          staticClass: \"header-anchor\",\n          attrs: {\n            href: \"#creating-a-multi-pass-blur-effect\",\n            \"aria-hidden\": \"true\"\n          }\n        },\n        [_vm._v(\"#\")]\n      ),\n      _vm._v(\" Creating a Multi-Pass Blur Effect\")\n    ])\n  },\n  function() {\n    var _vm = this\n    var _h = _vm.$createElement\n    var _c = _vm._self._c || _h\n    return _c(\"div\", { staticClass: \"language- extra-class\" }, [\n      _c(\"pre\", { pre: true, attrs: { class: \"language-text\" } }, [\n        _c(\"code\", [\n          _vm._v(\n            \"//\\tSoft Blur.vs\\nvarying vec2 left_coord;\\nvarying vec2 right_coord;\\nvarying vec2 above_coord;\\nvarying vec2 below_coord;\\n\\nvarying vec2 lefta_coord;\\nvarying vec2 righta_coord;\\nvarying vec2 leftb_coord;\\nvarying vec2 rightb_coord;\\n\\n\\nvoid main()\\n{\\n\\tisf_vertShaderInit();\\n\\tvec2 texc = vec2(isf_FragNormCoord[0],isf_FragNormCoord[1]);\\n\\tvec2 d = 1.0/RENDERSIZE;\\n\\n\\tleft_coord = clamp(vec2(texc.xy + vec2(-d.x , 0)),0.0,1.0);\\n\\tright_coord = clamp(vec2(texc.xy + vec2(d.x , 0)),0.0,1.0);\\n\\tabove_coord = clamp(vec2(texc.xy + vec2(0,d.y)),0.0,1.0);\\n\\tbelow_coord = clamp(vec2(texc.xy + vec2(0,-d.y)),0.0,1.0);\\n\\n\\tlefta_coord = clamp(vec2(texc.xy + vec2(-d.x , d.x)),0.0,1.0);\\n\\trighta_coord = clamp(vec2(texc.xy + vec2(d.x , d.x)),0.0,1.0);\\n\\tleftb_coord = clamp(vec2(texc.xy + vec2(-d.x , -d.x)),0.0,1.0);\\n\\trightb_coord = clamp(vec2(texc.xy + vec2(d.x , -d.x)),0.0,1.0);\\n}\\n\"\n          )\n        ])\n      ])\n    ])\n  },\n  function() {\n    var _vm = this\n    var _h = _vm.$createElement\n    var _c = _vm._self._c || _h\n    return _c(\"div\", { staticClass: \"language- extra-class\" }, [\n      _c(\"pre\", { pre: true, attrs: { class: \"language-text\" } }, [\n        _c(\"code\", [\n          _vm._v(\n            '/*{\\n\\t\"CREDIT\": \"by VIDVOX\",\\n\\t\"ISFVSN\": \"2\",\\n\\t\"CATEGORIES\": [\\n\\t\\t\"Blur\"\\n\\t],\\n\\t\"INPUTS\": [\\n\\t\\t{\\n\\t\\t\\t\"NAME\": \"inputImage\",\\n\\t\\t\\t\"TYPE\": \"image\"\\n\\t\\t},\\n\\t\\t{\\n\\t\\t\\t\"NAME\": \"softness\",\\n\\t\\t\\t\"TYPE\": \"float\",\\n\\t\\t\\t\"MIN\": 0.0,\\n\\t\\t\\t\"MAX\": 1.0,\\n\\t\\t\\t\"DEFAULT\": 0.9\\n\\t\\t},\\n\\t\\t{\\n\\t\\t\\t\"NAME\": \"depth\",\\n\\t\\t\\t\"TYPE\": \"float\",\\n\\t\\t\\t\"MIN\": 1.0,\\n\\t\\t\\t\"MAX\": 10.0,\\n\\t\\t\\t\"DEFAULT\": 10.0\\n\\t\\t}\\n\\t],\\n\\t\"PASSES\": [\\n\\t\\t{\\n\\t\\t\\t\"TARGET\": \"smaller\",\\n\\t\\t\\t\"WIDTH\": \"max(floor($WIDTH*0.02),1.0)\",\\n\\t\\t\\t\"HEIGHT\": \"max(floor($HEIGHT*0.02),1.0)\"\\n\\t\\t},\\n\\t\\t{\\n\\t\\t\\t\"TARGET\": \"small\",\\n\\t\\t\\t\"WIDTH\": \"max(floor($WIDTH*0.25),1.0)\",\\n\\t\\t\\t\"HEIGHT\": \"max(floor($HEIGHT*0.25),1.0)\"\\n\\t\\t},\\n\\t\\t{\\n\\t\\t\\n\\t\\t}\\n\\t]\\n}*/\\n\\n\\n//\\tA simple three pass blur – first reduce the size, then do a weighted blur, then do the same thing \\n\\n\\nvarying vec2 left_coord;\\nvarying vec2 right_coord;\\nvarying vec2 above_coord;\\nvarying vec2 below_coord;\\n\\nvarying vec2 lefta_coord;\\nvarying vec2 righta_coord;\\nvarying vec2 leftb_coord;\\nvarying vec2 rightb_coord;\\n\\nvoid main()\\n{\\n\\t\\n\\tvec4 color = IMG_THIS_NORM_PIXEL(inputImage);\\n\\tvec4 colorL = IMG_NORM_PIXEL(inputImage, left_coord);\\n\\tvec4 colorR = IMG_NORM_PIXEL(inputImage, right_coord);\\n\\tvec4 colorA = IMG_NORM_PIXEL(inputImage, above_coord);\\n\\tvec4 colorB = IMG_NORM_PIXEL(inputImage, below_coord);\\n\\n\\tvec4 colorLA = IMG_NORM_PIXEL(inputImage, lefta_coord);\\n\\tvec4 colorRA = IMG_NORM_PIXEL(inputImage, righta_coord);\\n\\tvec4 colorLB = IMG_NORM_PIXEL(inputImage, leftb_coord);\\n\\tvec4 colorRB = IMG_NORM_PIXEL(inputImage, rightb_coord);\\n\\n\\tvec4 avg = (color + colorL + colorR + colorA + colorB + colorLA + colorRA + colorLB + colorRB) / 9.0;\\n\\t\\n\\tif (PASSINDEX == 1)\\t{\\n\\t\\tvec4 blur = IMG_THIS_NORM_PIXEL(smaller);\\n\\t\\tavg = mix(color, (avg + depth*blur)/(1.0+depth), softness);\\n\\t}\\n\\telse if (PASSINDEX == 2)\\t{\\n\\t\\tvec4 blur = IMG_THIS_NORM_PIXEL(small);\\n\\t\\tavg = mix(color, (avg + depth*blur)/(1.0+depth), softness);\\n\\t}\\n\\tgl_FragColor = avg;\\n}\\n'\n          )\n        ])\n      ])\n    ])\n  },\n  function() {\n    var _vm = this\n    var _h = _vm.$createElement\n    var _c = _vm._self._c || _h\n    return _c(\"p\", [\n      _vm._v(\"Looking at the JSON blob in the \"),\n      _c(\"code\", [_vm._v(\"PASSES\")]),\n      _vm._v(\n        \" section, we can see that there are three render passes.  The first two render passes use the \"\n      ),\n      _c(\"code\", [_vm._v(\"WIDTH\")]),\n      _vm._v(\" and \"),\n      _c(\"code\", [_vm._v(\"HEIGHT\")]),\n      _vm._v(\n        \" attributes to resize the image being passed in.  This is a useful trick when creating multi-pass blur effects that averages together pixels during the size reduction and makes those averages the new neighboring pixels where they can be processed by the kernel.\"\n      )\n    ])\n  },\n  function() {\n    var _vm = this\n    var _h = _vm.$createElement\n    var _c = _vm._self._c || _h\n    return _c(\"p\", [\n      _vm._v(\n        \"On each rendering pass the basic Box Blur kernel is applied and sent to the output.  When the \"\n      ),\n      _c(\"code\", [_vm._v(\"PASSINDEX\")]),\n      _vm._v(\n        \" is 1 or 2 (on the 2nd and third render passes), the result of the Box Blur is combined with the result from the previous pass.  Instead of directly changing the kernel, the declared \"\n      ),\n      _c(\"code\", [_vm._v(\"INPUT\")]),\n      _vm._v(\" variables are used to adjust the amount of this blending.\")\n    ])\n  },\n  function() {\n    var _vm = this\n    var _h = _vm.$createElement\n    var _c = _vm._self._c || _h\n    return _c(\n      \"h2\",\n      {\n        attrs: { id: \"other-uses-of-persistent-buffers-and-multi-pass-shaders\" }\n      },\n      [\n        _c(\n          \"a\",\n          {\n            staticClass: \"header-anchor\",\n            attrs: {\n              href: \"#other-uses-of-persistent-buffers-and-multi-pass-shaders\",\n              \"aria-hidden\": \"true\"\n            }\n          },\n          [_vm._v(\"#\")]\n        ),\n        _vm._v(\" Other uses of persistent buffers and multi-pass shaders\")\n      ]\n    )\n  },\n  function() {\n    var _vm = this\n    var _h = _vm.$createElement\n    var _c = _vm._self._c || _h\n    return _c(\"h3\", { attrs: { id: \"conway-s-game-of-life\" } }, [\n      _c(\n        \"a\",\n        {\n          staticClass: \"header-anchor\",\n          attrs: { href: \"#conway-s-game-of-life\", \"aria-hidden\": \"true\" }\n        },\n        [_vm._v(\"#\")]\n      ),\n      _vm._v(\" Conway's Game of Life\")\n    ])\n  },\n  function() {\n    var _vm = this\n    var _h = _vm.$createElement\n    var _c = _vm._self._c || _h\n    return _c(\"pre\", [\n      _c(\"code\", [\n        _vm._v(\n          'The universe of the Game of Life is an infinite two-dimensional orthogonal grid of square cells, each of which is in one of two possible states, alive or dead, or \"populated\" or \"unpopulated\". Every cell interacts with its eight neighbours, which are the cells that are horizontally, vertically, or diagonally adjacent. At each step in time, the following transitions occur:\\n\\n- Any live cell with fewer than two live neighbours dies, as if caused by underpopulation.\\n- Any live cell with two or three live neighbours lives on to the next generation.\\n- Any live cell with more than three live neighbours dies, as if by overpopulation.\\n- Any dead cell with exactly three live neighbours becomes a live cell, as if by reproduction.\\n'\n        )\n      ])\n    ])\n  },\n  function() {\n    var _vm = this\n    var _h = _vm.$createElement\n    var _c = _vm._self._c || _h\n    return _c(\"p\", [\n      _vm._v(\n        \"For this shader we can once again re-use the basic convolution vertex shader and include the matching \"\n      ),\n      _c(\"code\", [_vm._v(\"varying\")]),\n      _vm._v(\" variables in the fragment shader below.\")\n    ])\n  },\n  function() {\n    var _vm = this\n    var _h = _vm.$createElement\n    var _c = _vm._self._c || _h\n    return _c(\"div\", { staticClass: \"language- extra-class\" }, [\n      _c(\"pre\", { pre: true, attrs: { class: \"language-text\" } }, [\n        _c(\"code\", [\n          _vm._v(\n            '/*{\\n\\t\"DESCRIPTION\": \"Based on Conway\\'s Game of Life\",\\n\\t\"CREDIT\": \"VIDVOX\",\\n\\t\"ISFVSN\": \"2\",\\n\\t\"CATEGORIES\": [\\n\\t\\t\"Generator\"\\n\\t],\\n\\t\"INPUTS\": [\\n\\t\\t{\\n\\t\\t\\t\"NAME\": \"restartNow\",\\n\\t\\t\\t\"TYPE\": \"event\"\\n\\t\\t},\\n\\t\\t{\\n\\t\\t\\t\"NAME\": \"startThresh\",\\n\\t\\t\\t\"TYPE\": \"float\",\\n\\t\\t\\t\"DEFAULT\": 0.5,\\n\\t\\t\\t\"MIN\": 0.0,\\n\\t\\t\\t\"MAX\": 1.0\\n\\t\\t}\\n\\t],\\n\\t\"PASSES\": [\\n\\t\\t{\\n\\t\\t\\t\"TARGET\":\"lastData\",\\n\\t\\t\\t\"PERSISTENT\": true\\n\\t\\t}\\n\\t]\\n\\t\\n}*/\\n\\n/*\\n\\nAny live cell with fewer than two live neighbours dies, as if caused by under-population.\\nAny live cell with two or three live neighbours lives on to the next generation.\\nAny live cell with more than three live neighbours dies, as if by over-population.\\nAny dead cell with exactly three live neighbours becomes a live cell, as if by reproduction.\\n\\n*/\\n\\nvarying vec2 left_coord;\\nvarying vec2 right_coord;\\nvarying vec2 above_coord;\\nvarying vec2 below_coord;\\n\\nvarying vec2 lefta_coord;\\nvarying vec2 righta_coord;\\nvarying vec2 leftb_coord;\\nvarying vec2 rightb_coord;\\n\\n//\\tused to get the grayscale version of a pixel\\nfloat gray(vec4 n)\\n{\\n\\treturn (n.r + n.g + n.b)/3.0;\\n}\\n\\n//\\tused to randomize the start state\\nfloat rand(vec2 co){\\n    return fract(sin(dot(co.xy ,vec2(12.9898,78.233))) * 43758.5453);\\n}\\n\\nvoid main()\\t{\\n\\tvec4\\t\\tinputPixelColor = vec4(0.0);\\n\\tvec2\\t\\tloc = gl_FragCoord.xy;\\n\\t\\n\\t//\\tif we are starting or the restartNow event is active, randomize\\n\\tif ((FRAMEINDEX < 1)||(restartNow))\\t{\\n\\t\\t//\\trandomize the start conditions\\n\\t\\tfloat\\talive = rand(vec2(TIME+1.0,2.1*TIME+0.1)*loc);\\n\\t\\tif (alive > 1.0 - startThresh)\\t{\\n\\t\\t\\tinputPixelColor = vec4(1.0);\\n\\t\\t}\\n\\t}\\n\\telse\\t{\\n\\t\\tvec4\\tcolor = IMG_PIXEL(lastData, loc);\\n\\t\\tvec4\\tcolorL = IMG_PIXEL(lastData, left_coord);\\n\\t\\tvec4\\tcolorR = IMG_PIXEL(lastData, right_coord);\\n\\t\\tvec4\\tcolorA = IMG_PIXEL(lastData, above_coord);\\n\\t\\tvec4\\tcolorB = IMG_PIXEL(lastData, below_coord);\\n\\n\\t\\tvec4\\tcolorLA = IMG_PIXEL(lastData, lefta_coord);\\n\\t\\tvec4\\tcolorRA = IMG_PIXEL(lastData, righta_coord);\\n\\t\\tvec4\\tcolorLB = IMG_PIXEL(lastData, leftb_coord);\\n\\t\\tvec4\\tcolorRB = IMG_PIXEL(lastData, rightb_coord);\\n\\t\\t\\n\\t\\tfloat\\tneighborSum = gray(colorL + colorR + colorA + colorB + colorLA + colorRA + colorLB + colorRB);\\n\\t\\tfloat\\tstate = gray(color);\\n\\t\\t\\n\\t\\t//\\tlive cell\\n\\t\\tif (state > 0.0)\\t{\\n\\t\\t\\tif (neighborSum < 2.0)\\t{\\n\\t\\t\\t\\t//\\tunder population\\n\\t\\t\\t\\tinputPixelColor = vec4(0.0);\\n\\t\\t\\t}\\n\\t\\t\\telse if (neighborSum < 4.0)\\t{\\n\\t\\t\\t\\t//\\tstatus quo\\n\\t\\t\\t\\tinputPixelColor = vec4(1.0);\\n\\t\\t\\t}\\n\\t\\t\\telse\\t{\\n\\t\\t\\t\\t//\\tover population\\n\\t\\t\\t\\tinputPixelColor = vec4(0.0);\\n\\t\\t\\t}\\n\\t\\t}\\n\\t\\t//\\tdead cell\\n\\t\\telse\\t{\\n\\t\\t\\tif ((neighborSum > 2.0)&&(neighborSum < 4.0))\\t{\\n\\t\\t\\t\\t//\\treproduction\\n\\t\\t\\t\\tinputPixelColor = vec4(1.0);\\n\\t\\t\\t}\\n\\t\\t\\telse if (neighborSum < 2.0)\\t{\\n\\t\\t\\t\\t//\\tstay dead\\n\\t\\t\\t}\\n\\t\\t}\\n\\t}\\n\\t\\n\\tgl_FragColor = inputPixelColor;\\n}\\n'\n          )\n        ])\n      ])\n    ])\n  },\n  function() {\n    var _vm = this\n    var _h = _vm.$createElement\n    var _c = _vm._self._c || _h\n    return _c(\"p\", [\n      _vm._v(\"Walking through this code, the initial \"),\n      _c(\"code\", [_vm._v(\"if\")]),\n      _vm._v(\n        \" statement is used to determine if the shader needs to randomize the state.  This happens under one of two conditions, either the \"\n      ),\n      _c(\"code\", [_vm._v(\"FRAMEINDEX\")]),\n      _vm._v(\" is 0 (the first frame) or the \"),\n      _c(\"code\", [_vm._v(\"restartNow\")]),\n      _vm._v(\" uniform (declared as an \"),\n      _c(\"code\", [_vm._v(\"event\")]),\n      _vm._v(\n        \" type in the JSON blob) has been set to true by the host application.  The initial state is created by calling our custom rand() function which creates pseudo-random numbers between 0.0 and 1.0.  When these numbers are above the startThresh, the pixel starts as alive.\"\n      )\n    ])\n  },\n  function() {\n    var _vm = this\n    var _h = _vm.$createElement\n    var _c = _vm._self._c || _h\n    return _c(\"p\", [\n      _vm._v(\n        \"When the state is not being randomized, we follow the ruleset.  There are two pieces of information we need to collect and based on those there can result in four possible outcomes.  In particular we need to know the current alive / dead state of the current pixel (1 or 0) and we need to know the summation of the states of the neighboring pixels.  Here the \"\n      ),\n      _c(\"code\", [_vm._v(\"state\")]),\n      _vm._v(\" variable holds the state of the current pixel and \"),\n      _c(\"code\", [_vm._v(\"neighborSum\")]),\n      _vm._v(\" is used to hold the sum of the surrounding 8 pixels.\")\n    ])\n  },\n  function() {\n    var _vm = this\n    var _h = _vm.$createElement\n    var _c = _vm._self._c || _h\n    return _c(\"p\", [\n      _vm._v(\"Once this information is collected we can create a set of \"),\n      _c(\"code\", [_vm._v(\"if\")]),\n      _vm._v(\n        \" statements based on their values, starting with whether or not the state is 1 or 0.  When the cell is alive, it can die as a result of over or under population, otherwise it stays the same.  When the cell is dead, it can become alive due to reproduction if there are enough neighboring living cells.\"\n      )\n    ])\n  },\n  function() {\n    var _vm = this\n    var _h = _vm.$createElement\n    var _c = _vm._self._c || _h\n    return _c(\"ul\", [\n      _c(\"li\", [\n        _vm._v(\n          \"Create a version that uses the RGB channels to run three different simulations in a single output.\"\n        )\n      ]),\n      _vm._v(\" \"),\n      _c(\"li\", [\n        _vm._v(\n          \"Add an option to switch between pseudo-random numbers and sin waves for the starting state.\"\n        )\n      ]),\n      _vm._v(\" \"),\n      _c(\"li\", [\n        _vm._v(\"Add options for random birth and random death of cells.\")\n      ]),\n      _vm._v(\" \"),\n      _c(\"li\", [\n        _vm._v(\"Change the rules to increase or decrease the birth rate.\")\n      ])\n    ])\n  }\n]\nrender._withStripped = true\n\nexport { render, staticRenderFns }"]}